# [AP-KANON-FINAL] START: src/ui/admin_prompt.py â€” ko/en canonicalization + robust extract + prefill handshake
from __future__ import annotations
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import json
import yaml
import streamlit as st

# âœ… ì§„ì§œ ì‚¬ì´ë“œë°”(Single Source of Truth)
try:
    from .utils.sider import render_sidebar
except Exception:
    from src.ui.utils.sider import render_sidebar  # fallback

# ---- SSOT: UI Widget Keys ----------------------------------------------------
K_PERSONA  = "persona_text"
K_GRAMMAR  = "grammar_prompt"
K_SENTENCE = "sentence_prompt"
K_PASSAGE  = "passage_prompt"

# ---- canon helpers -----------------------------------------------------------
def _norm_token(x: Any) -> str:
    """ê³µë°±/ëŒ€ì†Œë¬¸ì/êµ¬ë‘ì  ì˜í–¥ ìµœì†Œí™”. (í•œê¸€ í¬í•¨)"""
    s = str(x or "").strip().lower()
    return "".join(ch for ch in s if ch.isalnum())

def _coerce_yaml_to_text(v: Any) -> str:
    """ë¬¸ìì—´ì´ ì•„ë‹ˆì–´ë„ ë³´ê¸° ì¢‹ê²Œ ë¬¸ìì—´í™”(dict/list ì§€ì›)."""
    if v is None:
        return ""
    if isinstance(v, str):
        return v
    if isinstance(v, dict):
        for k in ("prompt", "text", "full", "system", "value", "content"):
            vs = v.get(k)
            if isinstance(vs, str) and vs.strip():
                return vs
        return json.dumps(v, ensure_ascii=False, indent=2)
    if isinstance(v, (list, tuple)):
        return "\n".join(str(x) for x in v)
    return str(v)

# â€”â€” 1ìˆœìœ„: core.modes ìœ í‹¸ì´ ìˆìœ¼ë©´ ì ê·¹ ì‚¬ìš©(ìˆì„ ìˆ˜ë„, ì—†ì„ ìˆ˜ë„)
def _canon_via_core_modes(label: str) -> Optional[str]:
    try:
        import src.core.modes as _m
    except Exception:
        return None
    # ê°€ëŠ¥í•œ ì—¬ëŸ¬ ì´ë¦„ì„ ì‹œë„ (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ)
    for cand in ("canon_mode", "canon_key", "normalize_mode", "normalize_key", "find_mode_by_label"):
        fn = getattr(_m, cand, None)
        if not callable(fn):
            continue
        try:
            res = fn(label)
        except Exception:
            continue
        # ë¬¸ìì—´ ë˜ëŠ” .key ë³´ìœ  ê°ì²´ ëª¨ë‘ ìˆ˜ìš©
        if isinstance(res, str):
            s = res.strip().lower()
            if s in ("grammar", "sentence", "passage"):
                return s
            # í•œêµ­ì–´ ë ˆì´ë¸”ì„ ëŒë ¤ì£¼ëŠ” êµ¬í˜„ì¼ ìˆ˜ë„ ìˆìŒ
            if s in ("ë¬¸ë²•", "ë¬¸ì¥", "ì§€ë¬¸"):
                return {"ë¬¸ë²•": "grammar", "ë¬¸ì¥": "sentence", "ì§€ë¬¸": "passage"}[s]
        key = getattr(res, "key", None)
        if isinstance(key, str) and key in ("grammar", "sentence", "passage"):
            return key
    return None

# â€”â€” 2ìˆœìœ„: ë‚´ì¥ ì‹œì†ŒëŸ¬ìŠ¤ + ë¶€ë¶„ì¼ì¹˜(â€œë¬¸ì¥êµ¬ì¡°ë¶„ì„â€ ë“±) ---------------------------
_SYNONYMS = {
    "grammar": {
        "grammar", "pt", "ë¬¸ë²•", "ë¬¸ë²•ì„¤ëª…", "ë¬¸ë²•í•´ì„¤", "ë¬¸ë²•ê·œì¹™", "í’ˆì‚¬", "í’ˆì‚¬íŒë³„",
        "ë¬¸ì¥ì„±ë¶„", "ë¬¸ë²•ê²€ì‚¬", "ë¬¸ë²•í’€ì´", "ë¬¸ë²• ë¬¸ì œ", "ë¬¸ë²•í•´ì„",
    },
    "sentence": {
        "sentence", "sent", "ë¬¸ì¥", "ë¬¸ì¥ë¶„ì„", "ë¬¸ì¥í•´ì„", "ë¬¸ì¥êµ¬ì¡°", "ë¬¸ì¥êµ¬ì¡°ë¶„ì„",
        "ë¬¸ì¥ì„±ë¶„ë¶„ì„", "ë¬¸ì¥ì™„ì„±", "ë¬¸ì¥êµ¬ì¡°í•´ì„", "ë¬¸ì¥êµ¬ì¡°íŒŒì•…",
    },
    "passage": {
        "passage", "para", "ì§€ë¬¸", "ì§€ë¬¸ë¶„ì„", "ë…í•´", "ë…í•´ì§€ë¬¸", "ë…í•´ë¶„ì„", "ì§€ë¬¸í•´ì„",
        "ë…í•´ ë¬¸ì œ", "ì¥ë¬¸", "ì¥ë¬¸ë…í•´",
    },
}
_SUBSTR_HINTS: List[Tuple[str, Tuple[str, ...]]] = [
    ("grammar", ("ë¬¸ë²•", "í’ˆì‚¬", "ì„±ë¶„")),
    ("sentence", ("ë¬¸ì¥", "êµ¬ì¡°", "ì„±ë¶„", "ì™„ì„±")),
    ("passage", ("ì§€ë¬¸", "ë…í•´", "ì¥ë¬¸")),
]

def _canon_mode_key(label_or_key: Any) -> str:
    """í•œêµ­ì–´/ì˜ë¬¸/ì•½ì–´ ë¼ë²¨ì„ í‘œì¤€ í‚¤('grammar'|'sentence'|'passage')ë¡œ ì •ê·œí™”."""
    s = str(label_or_key or "").strip()
    if not s:
        return ""
    # 1) core.modes ìš°ì„ 
    via_core = _canon_via_core_modes(s)
    if via_core:
        return via_core
    # 2) ë™ì˜ì–´ ì •ê·œí™”(ì •í™•ì¼ì¹˜)
    t = _norm_token(s)
    for key, names in _SYNONYMS.items():
        for name in names:
            if _norm_token(name) == t:
                return key
    # 3) ë¶€ë¶„ì¼ì¹˜ íŒíŠ¸(â€˜ë¬¸ì¥êµ¬ì¡°ë¶„ì„â€™, â€˜ë…í•´ ë¬¸ì œâ€™ ë“±)
    low = s.lower()
    for key, hints in _SUBSTR_HINTS:
        if any(h in low for h in hints):
            return key
    # 4) ì˜ë¬¸ ì¶•ì•½
    if t in ("pt", "mn", "mina"):
        return "sentence" if t != "pt" else "grammar"
    return ""

# ---- file resolve ------------------------------------------------------------
def _resolve_release_prompts_file() -> Path | None:
    """release/assets â†’ release â†’ ./assets â†’ ./ ìˆœìœ¼ë¡œ prompts.yaml íƒìƒ‰."""
    base = Path(st.session_state.get("_release_dir", "release")).resolve()
    for p in [base / "assets" / "prompts.yaml",
              base / "prompts.yaml",
              Path("assets/prompts.yaml").resolve(),
              Path("prompts.yaml").resolve()]:
        try:
            if p.exists() and p.is_file():
                return p
        except Exception:
            continue
    return None

# ---- robust extractor --------------------------------------------------------
def _extract_prompts(doc: Dict[str, Any]) -> Dict[str, str]:
    """
    ë‹¤ì–‘í•œ YAML ìŠ¤í‚¤ë§ˆë¥¼ **ê²¬ê³ í•˜ê²Œ** ìˆ˜ìš©í•´ UI í‚¤ë¡œ ë§¤í•‘í•œë‹¤.
    - Top-level í•œê¸€/ì˜ë¬¸ ë¼ë²¨(ë¬¸ì¥êµ¬ì¡°ë¶„ì„/ë¬¸ë²•ì„¤ëª…/ì§€ë¬¸ë¶„ì„ ë“±) â†’ ì •ê·œí™”
    - Nested: { mn:{sentence,passage} }, { pt:{grammar/prompt/...} } ë“±
    - List/Dict: { modes:[...]} ë˜ëŠ” { modes:{...} } / { ëª¨ë“œ: ... } / ê¸°íƒ€ ìœ ì‚¬ í‚¤ë„ ì¬ê·€ ìŠ¤ìº”
    - ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ë¶€ë¶„ì¼ì¹˜/ì‹œì†ŒëŸ¬ìŠ¤ë¡œ ì¶”ì • ë§¤í•‘
    """
    out = {K_PERSONA: "", K_GRAMMAR: "", K_SENTENCE: "", K_PASSAGE: ""}

    def _assign(canon: str, payload: Any) -> None:
        if not canon:
            return
        text = _coerce_yaml_to_text(payload)
        if not text:
            return
        if canon == "grammar":
            out[K_GRAMMAR] = text
        elif canon == "sentence":
            out[K_SENTENCE] = text
        elif canon == "passage":
            out[K_PASSAGE] = text

    def _maybe_persona(k: Any, v: Any) -> bool:
        kk = str(k or "").strip().lower()
        if kk in {"persona", "common", "profile", "system", "í˜ë¥´ì†Œë‚˜", "ê³µí†µ", "í”„ë¡œí•„"}:
            out[K_PERSONA] = _coerce_yaml_to_text(v)
            return True
        return False

    # 1) 1ì°¨: ì–•ì€ ë ˆë²¨ ìŠ¤ìº”
    for k, v in (doc or {}).items():
        if _maybe_persona(k, v):
            continue
        canon = _canon_mode_key(k)
        if canon:
            _assign(canon, v)

    # 2) mn/pt ë³´ì •
    mn = doc.get("mn") or doc.get("mina")
    if isinstance(mn, dict):
        for nk, nv in mn.items():
            _assign(_canon_mode_key(nk), nv)
    pt = doc.get("pt") if isinstance(doc.get("pt"), dict) else None
    if isinstance(pt, dict) and not out[K_GRAMMAR]:
        # pt ë‚´ë¶€ì—ì„œ ë¬¸ë²• í…ìŠ¤íŠ¸ ì°¾ê¸°
        for k in ("grammar", "prompt", "text", "full", "system", "ì„¤ëª…"):
            if k in pt:
                _assign("grammar", pt[k])
                break

    # 3) modes ì„¹ì…˜: dict/list/í•œê¸€í‚¤ ëª¨ë‘ ìˆ˜ìš©
    for key in ("modes", "ëª¨ë“œ", "mode_prompts", "modeprompts", "prompts_by_mode"):
        sect = doc.get(key)
        if isinstance(sect, dict):
            for mk, mv in sect.items():
                canon = _canon_mode_key(mk)
                if canon:
                    _assign(canon, mv)
        elif isinstance(sect, list):
            for entry in sect:
                if not isinstance(entry, dict):
                    continue
                label = entry.get("key") or entry.get("label") or entry.get("name") or entry.get("ë¼ë²¨")
                canon = _canon_mode_key(label)
                # payload í›„ë³´ ìš°ì„ ìˆœìœ„
                text = None
                for tk in ("prompt", "text", "full", "system", "value", "content", "ì§€ì‹œ", "ê·œì¹™"):
                    if isinstance(entry.get(tk), str) and entry.get(tk).strip():
                        text = entry.get(tk)
                        break
                if text is None:
                    text = entry
                if canon:
                    _assign(canon, text)

    # 4) 2ì°¨: ì¬ê·€ ìŠ¤ìº”(ì•ˆì „í•œ ì œí•œ, ê¹Šì´â‰¤3)
    def _walk(node: Any, depth: int = 0) -> None:
        if depth >= 3:
            return
        if isinstance(node, dict):
            for k, v in node.items():
                if _maybe_persona(k, v):
                    continue
                canon = _canon_mode_key(k)
                if canon:
                    _assign(canon, v)
                _walk(v, depth + 1)
        elif isinstance(node, list):
            for it in node:
                _walk(it, depth + 1)

    _walk(doc)

    return out

def _load_prompts_from_release() -> tuple[Dict[str, str], Path]:
    p = _resolve_release_prompts_file()
    if not p:
        raise FileNotFoundError("prompts.yamlì„ release/assets ë˜ëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    with p.open("r", encoding="utf-8") as f:
        y = yaml.safe_load(f) or {}
    return _extract_prompts(y), p

# ---- prefill handshake (ì½œë°± rerun ê²½ê³  ì—†ì´ ì¦‰ì‹œ ë°˜ì˜) ----------------------
def _apply_pending_prefill() -> None:
    ss = st.session_state
    data = ss.pop("_PREFILL_PROMPTS", None)
    if isinstance(data, dict):
        ss[K_PERSONA]  = data.get(K_PERSONA,  "")
        ss[K_GRAMMAR]  = data.get(K_GRAMMAR,  "")
        ss[K_SENTENCE] = data.get(K_SENTENCE, "")
        ss[K_PASSAGE]  = data.get(K_PASSAGE,  "")

# ---- Page Main ---------------------------------------------------------------
def main() -> None:
    render_sidebar()

    # (1) í”„ë¦¬í•„ ì˜ˆì•½ë¶„ ì ìš©(ìœ„ì ¯ ìƒì„± ì „ì—)
    _apply_pending_prefill()

    # (2) í”Œë˜ì‹œ
    ok = st.session_state.pop("_flash_success", None)
    er = st.session_state.pop("_flash_error",   None)
    if ok: st.success(ok)
    if er: st.error(er)

    # (3) ìƒíƒœ ì ê²€
    with st.container(border=True):
        st.subheader("ğŸ” ìƒíƒœ ì ê²€", divider="gray")
        p = _resolve_release_prompts_file()
        if p: st.success(f"ê²½ë¡œ OK â€” prompts.yaml í™•ì¸: {p}")
        else: st.warning("prompts.yamlì„ release/assets ë˜ëŠ” ë£¨íŠ¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # (4) í¸ì§‘ UI â€” SSOT í‚¤
    st.markdown("### â‘  í˜ë¥´ì†Œë‚˜(ê³µí†µ)")
    st.text_area("ëª¨ë“  ëª¨ë“œì— ê³µí†µ ì ìš©", key=K_PERSONA, height=160, placeholder="í˜ë¥´ì†Œë‚˜ í…ìŠ¤íŠ¸...")

    st.markdown("### â‘¡ ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸(ì§€ì‹œ/ê·œì¹™)")
    c1, c2, c3 = st.columns(3)
    with c1: st.text_area("ë¬¸ë²•(Grammar) í”„ë¡¬í”„íŠ¸", key=K_GRAMMAR,  height=220, placeholder="ë¬¸ë²• ëª¨ë“  ì§€ì‹œ/ê·œì¹™...")
    with c2: st.text_area("ë¬¸ì¥(Sentence) í”„ë¡¬í”„íŠ¸", key=K_SENTENCE, height=220, placeholder="ë¬¸ì¥ ëª¨ë“  ì§€ì‹œ/ê·œì¹™...")
    with c3: st.text_area("ì§€ë¬¸(Passage) í”„ë¡¬í”„íŠ¸",  key=K_PASSAGE,  height=220, placeholder="ì§€ë¬¸ ëª¨ë“  ì§€ì‹œ/ê·œì¹™...")

    # (5) ì•¡ì…˜
    st.markdown("### â‘¢ ì•¡ì…˜")
    if st.button("ğŸ“¥ ìµœì‹  í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°(ë¦´ë¦¬ìŠ¤ ìš°ì„ )", use_container_width=True, key="btn_fetch_prompts"):
        try:
            texts, src = _load_prompts_from_release()
            # ì˜ˆì•½í‚¤ì— ì €ì¥ â†’ rerun â†’ ë‹¤ìŒ ëŸ°ì˜ 'ìœ„ì ¯ ìƒì„± ì „'ì— ì£¼ì…
            st.session_state["_PREFILL_PROMPTS"] = {
                K_PERSONA:  texts.get(K_PERSONA, ""),
                K_GRAMMAR:  texts.get(K_GRAMMAR, ""),
                K_SENTENCE: texts.get(K_SENTENCE, ""),
                K_PASSAGE:  texts.get(K_PASSAGE, ""),
            }
            st.session_state["_last_prompts_source"] = str(src)
            st.session_state["_flash_success"] = f"ë¦´ë¦¬ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {src}"
            st.rerun()
        except FileNotFoundError as e:
            st.session_state["_flash_error"] = str(e); st.rerun()
        except Exception:
            st.session_state["_flash_error"] = "í”„ë¡¬í”„íŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."; st.rerun()

    if st.session_state.get("_last_prompts_source"):
        st.caption(f"ìµœê·¼ ì†ŒìŠ¤: {st.session_state['_last_prompts_source']}")

if __name__ == "__main__":
    main()
# [AP-KANON-FINAL] END
