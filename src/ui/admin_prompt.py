# [AP-KANON-VERT] START: src/ui/admin_prompt.py â€” vertical layout + ko/en canonicalization + persona-safe + prefill + save/publish
from __future__ import annotations
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import json
import yaml
import requests as req
import streamlit as st

# âœ… ì‚¬ì´ë“œë°”(SSOT)
try:
    from .utils.sider import render_sidebar
except Exception:
    from src.ui.utils.sider import render_sidebar  # fallback

# âœ… persist ê²½ë¡œ(ë¡œì»¬ ì €ì¥ í´ë°±)
try:
    from src.core.persist import effective_persist_dir
except Exception:
    effective_persist_dir = lambda: Path.home() / ".maic" / "persist"  # type: ignore

# ---- UI Widget Keys (SSOT) ---------------------------------------------------
K_PERSONA  = "persona_text"
K_GRAMMAR  = "grammar_prompt"
K_SENTENCE = "sentence_prompt"
K_PASSAGE  = "passage_prompt"

# ---- canon helpers -----------------------------------------------------------
def _norm_token(x: Any) -> str:
    s = str(x or "").strip().lower()
    return "".join(ch for ch in s if ch.isalnum())

def _coerce_yaml_to_text(v: Any) -> str:
    """
    dict/listë„ ë³´ê¸° ì¢‹ê²Œ ë¬¸ìì—´í™”.
    âš ï¸ dictì¼ ë•ŒëŠ” 'prompt'/'text'ë¥¼ ìš°ì„ , 'full'/'system'ì€ ìµœí›„ í´ë°±.
    """
    if v is None:
        return ""
    if isinstance(v, str):
        return v
    if isinstance(v, dict):
        for k in ("prompt", "text"):
            s = v.get(k)
            if isinstance(s, str) and s.strip():
                return s
        for k in ("full", "system", "value", "content"):
            s = v.get(k)
            if isinstance(s, str) and s.strip():
                return s
        return json.dumps(v, ensure_ascii=False, indent=2)
    if isinstance(v, (list, tuple)):
        return "\n".join(str(x) for x in v)
    return str(v)

def _canon_via_core_modes(label: str) -> Optional[str]:
    """ê°€ëŠ¥í•˜ë©´ core.modesì˜ ì •ê·œí™” ìœ í‹¸ì„ ìš°ì„  ì‚¬ìš©."""
    try:
        import src.core.modes as _m
    except Exception:
        return None
    for cand in ("canon_mode", "canon_key", "normalize_mode", "normalize_key", "find_mode_by_label"):
        fn = getattr(_m, cand, None)
        if not callable(fn):
            continue
        try:
            res = fn(label)
        except Exception:
            continue
        if isinstance(res, str):
            s = res.strip().lower()
            if s in ("grammar", "sentence", "passage"):
                return s
            if s in ("ë¬¸ë²•", "ë¬¸ì¥", "ì§€ë¬¸"):
                return {"ë¬¸ë²•": "grammar", "ë¬¸ì¥": "sentence", "ì§€ë¬¸": "passage"}[s]
        key = getattr(res, "key", None)
        if isinstance(key, str) and key in ("grammar", "sentence", "passage"):
            return key
    return None

_SYNONYMS = {
    "grammar": {"grammar", "pt", "ë¬¸ë²•", "ë¬¸ë²•ì„¤ëª…", "ë¬¸ë²•í•´ì„¤", "ë¬¸ë²•ê·œì¹™", "í’ˆì‚¬", "í’ˆì‚¬íŒë³„", "ë¬¸ì¥ì„±ë¶„", "ë¬¸ë²•ê²€ì‚¬", "ë¬¸ë²•í’€ì´", "ë¬¸ë²• ë¬¸ì œ"},
    "sentence": {"sentence", "sent", "ë¬¸ì¥", "ë¬¸ì¥ë¶„ì„", "ë¬¸ì¥í•´ì„", "ë¬¸ì¥êµ¬ì¡°", "ë¬¸ì¥êµ¬ì¡°ë¶„ì„", "ë¬¸ì¥ì„±ë¶„ë¶„ì„", "ë¬¸ì¥ì™„ì„±", "ë¬¸ì¥êµ¬ì¡°í•´ì„", "ë¬¸ì¥êµ¬ì¡°íŒŒì•…"},
    "passage": {"passage", "para", "ì§€ë¬¸", "ì§€ë¬¸ë¶„ì„", "ë…í•´", "ë…í•´ì§€ë¬¸", "ë…í•´ë¶„ì„", "ì§€ë¬¸í•´ì„", "ë…í•´ ë¬¸ì œ", "ì¥ë¬¸", "ì¥ë¬¸ë…í•´"},
}
_SUBSTR_HINTS: List[Tuple[str, Tuple[str, ...]]] = [
    ("grammar", ("ë¬¸ë²•", "í’ˆì‚¬", "ì„±ë¶„")),
    ("sentence", ("ë¬¸ì¥", "êµ¬ì¡°", "ì„±ë¶„", "ì™„ì„±")),
    ("passage", ("ì§€ë¬¸", "ë…í•´", "ì¥ë¬¸")),
]

def _canon_mode_key(label_or_key: Any) -> str:
    """í•œêµ­ì–´/ì˜ë¬¸/ì•½ì–´ ë¼ë²¨ì„ í‘œì¤€ í‚¤('grammar'|'sentence'|'passage')ë¡œ ì •ê·œí™”."""
    s = str(label_or_key or "").strip()
    if not s:
        return ""
    via = _canon_via_core_modes(s)
    if via:
        return via
    t = _norm_token(s)
    for key, names in _SYNONYMS.items():
        if any(_norm_token(n) == t for n in names):
            return key
    low = s.lower()
    for key, hints in _SUBSTR_HINTS:
        if any(h in low for h in hints):
            return key
    if t in ("pt", "mn", "mina"):
        return "sentence" if t != "pt" else "grammar"
    return ""

# ---- file resolve ------------------------------------------------------------
def _resolve_release_prompts_file() -> Path | None:
    """release/assets â†’ release â†’ ./assets â†’ ./ ìˆœìœ¼ë¡œ prompts.yaml íƒìƒ‰."""
    base = Path(st.session_state.get("_release_dir", "release")).resolve()
    for p in [base / "assets" / "prompts.yaml",
              base / "prompts.yaml",
              Path("assets/prompts.yaml").resolve(),
              Path("prompts.yaml").resolve()]:
        try:
            if p.exists() and p.is_file():
                return p
        except Exception:
            continue
    return None

# ---- persona-safe helpers ----------------------------------------------------
def _strip_persona_prefix(text: str, persona: str) -> str:
    """
    'full'(=í˜ë¥´ì†Œë‚˜+ì§€ì‹œë¬¸)ì—ì„œ í˜ë¥´ì†Œë‚˜ê°€ 'ì•ë¶€ë¶„'ì— ë¶™ì€ ê²½ìš°ë§Œ ì•ˆì „ ì œê±°.
    ì™„ì „ ì¼ì¹˜ ë˜ëŠ” ê·¼ì ‘(head hit)ë§Œ ì œê±°, ì¤‘ê°„/ë í¬í•¨ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ.
    """
    if not text or not persona:
        return text
    t = text.lstrip()
    p = persona.strip()
    if not p:
        return text
    if t.startswith(p):
        return t[len(p):].lstrip(" \r\n-*")
    head = p[:64]
    if head and head in t[:512]:
        idx = t.find(head)
        if 0 <= idx <= 8:
            return t[idx + len(head):].lstrip(" \r\n-*")
    return text

# ---- robust extractor --------------------------------------------------------
def _extract_prompts(doc: Dict[str, Any]) -> Dict[str, str]:
    """
    ë‹¤ì–‘í•œ YAML ìŠ¤í‚¤ë§ˆë¥¼ ê²¬ê³ í•˜ê²Œ ìˆ˜ìš©í•´ UI í‚¤ë¡œ ë§¤í•‘.
    - Top-level í•œ/ì˜ ë¼ë²¨(ë¬¸ì¥êµ¬ì¡°ë¶„ì„/ë¬¸ë²•ì„¤ëª…/ì§€ë¬¸ë¶„ì„ ë“±) â†’ ì •ê·œí™”
    - Nested: { mn:{ sentence, passage } }, { pt:{ grammar/prompt/text/... } }
    - modes: dict/list/í•œê¸€í‚¤
    - 'full'ë§Œ ìˆëŠ” ê²½ìš° í˜ë¥´ì†Œë‚˜ prefix-strip
    """
    out = {K_PERSONA: "", K_GRAMMAR: "", K_SENTENCE: "", K_PASSAGE: ""}

    # 0) í˜ë¥´ì†Œë‚˜ 1ì°¨ ìˆ˜ì§‘
    def _maybe_persona(k: Any, v: Any) -> bool:
        kk = str(k or "").strip().lower()
        if kk in {"persona", "common", "profile", "system", "í˜ë¥´ì†Œë‚˜", "ê³µí†µ", "í”„ë¡œí•„"}:
            out[K_PERSONA] = _coerce_yaml_to_text(v)
            return True
        return False

    for k, v in (doc or {}).items():
        if _maybe_persona(k, v):
            continue

    # pt/mn ë‚´ë¶€ systemë„ ì „ì—­ í˜ë¥´ì†Œë‚˜ í›„ë³´ë¡œ í¡ìˆ˜(ë¹„ì–´ ìˆì„ ë•Œë§Œ)
    for nested_key in ("pt", "mn", "mina"):
        nv = doc.get(nested_key)
        if isinstance(nv, dict) and not out[K_PERSONA]:
            sys_txt = nv.get("system")
            if isinstance(sys_txt, str) and sys_txt.strip():
                out[K_PERSONA] = sys_txt

    persona_hint = out[K_PERSONA]

    def _assign(canon: str, payload: Any) -> None:
        if not canon:
            return
        raw = payload
        txt = _coerce_yaml_to_text(raw)
        # dictì—ì„œ prompt/textê°€ ì—†ì–´ full/systemì„ ì“°ê²Œ ëœ ê²½ìš° â†’ í˜ë¥´ì†Œë‚˜ ì œê±° ì‹œë„
        if isinstance(raw, dict):
            has_direct = any(isinstance(raw.get(k), str) and raw.get(k).strip() for k in ("prompt", "text"))
            if not has_direct:
                txt = _strip_persona_prefix(txt, persona_hint)
        if not txt:
            return
        if canon == "grammar":
            out[K_GRAMMAR] = txt
        elif canon == "sentence":
            out[K_SENTENCE] = txt
        elif canon == "passage":
            out[K_PASSAGE] = txt

    # 1) ì–•ì€ ìŠ¤ìº”(ë¼ë²¨ ì •ê·œí™”)
    for k, v in (doc or {}).items():
        if _maybe_persona(k, v):
            continue
        _assign(_canon_mode_key(k), v)

    # 2) mn/pt ë³´ì •
    mn = doc.get("mn") or doc.get("mina")
    if isinstance(mn, dict):
        for nk, nv in mn.items():
            _assign(_canon_mode_key(nk), nv)

    pt = doc.get("pt") if isinstance(doc.get("pt"), dict) else None
    if isinstance(pt, dict):
        if not out[K_GRAMMAR]:
            for k in ("grammar", "prompt", "text", "full"):
                if k in pt:
                    _assign("grammar", pt[k])
                    break
        # pt.systemì€ ì´ë¯¸ í˜ë¥´ì†Œë‚˜ í›„ë³´ë¡œë§Œ ì‚¬ìš©

    # 3) modes ì„¹ì…˜: dict/list/í•œê¸€í‚¤
    for key in ("modes", "ëª¨ë“œ", "mode_prompts", "modeprompts", "prompts_by_mode"):
        sect = doc.get(key)
        if isinstance(sect, dict):
            for mk, mv in sect.items():
                _assign(_canon_mode_key(mk), mv)
        elif isinstance(sect, list):
            for e in sect:
                if not isinstance(e, dict):
                    continue
                label = e.get("key") or e.get("label") or e.get("name") or e.get("ë¼ë²¨")
                canon = _canon_mode_key(label)
                payload = e  # prompt/textê°€ ì—†ìœ¼ë©´ fullì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ e ê·¸ëŒ€ë¡œ ë„˜ê²¨ strip ì²˜ë¦¬
                if canon:
                    _assign(canon, payload)

    # 4) ì œí•œ ì¬ê·€(â‰¤3)
    def _walk(node: Any, depth: int = 0) -> None:
        if depth >= 3:
            return
        if isinstance(node, dict):
            for k, v in node.items():
                if _maybe_persona(k, v):
                    continue
                canon = _canon_mode_key(k)
                if canon:
                    _assign(canon, v)
                _walk(v, depth + 1)
        elif isinstance(node, list):
            for it in node:
                _walk(it, depth + 1)

    _walk(doc)
    return out

def _load_prompts_from_release() -> tuple[Dict[str, str], Path]:
    p = _resolve_release_prompts_file()
    if not p:
        raise FileNotFoundError("prompts.yamlì„ release/assets ë˜ëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    with p.open("r", encoding="utf-8") as f:
        y = yaml.safe_load(f) or {}
    return _extract_prompts(y), p

# ---- prefill handshake -------------------------------------------------------
def _apply_pending_prefill() -> None:
    ss = st.session_state
    data = ss.pop("_PREFILL_PROMPTS", None)
    if isinstance(data, dict):
        ss[K_PERSONA]  = data.get(K_PERSONA,  "")
        ss[K_GRAMMAR]  = data.get(K_GRAMMAR,  "")
        ss[K_SENTENCE] = data.get(K_SENTENCE, "")
        ss[K_PASSAGE]  = data.get(K_PASSAGE,  "")

# ---- yaml build/validate/save/publish ---------------------------------------
def _build_yaml_from_fields() -> str:
    doc = {
        "version": "auto",
        "persona": st.session_state.get(K_PERSONA, "") or "",
        "modes": [
            {"key": "grammar",  "prompt": st.session_state.get(K_GRAMMAR,  "") or ""},
            {"key": "sentence", "prompt": st.session_state.get(K_SENTENCE, "") or ""},
            {"key": "passage",  "prompt": st.session_state.get(K_PASSAGE,  "") or ""},
        ],
    }
    return yaml.safe_dump(doc, allow_unicode=True, sort_keys=False)

def _validate_yaml_text(text: str) -> tuple[bool, List[str]]:
    msgs: List[str] = []
    try:
        y = yaml.safe_load(text) or {}
    except Exception as e:
        return False, [f"YAML íŒŒì‹± ì‹¤íŒ¨: {e}"]
    d = json.loads(json.dumps(y))  # normalize
    ok_modes = isinstance(d.get("modes"), list) and len(d["modes"]) > 0
    has_any = any(k in d for k in ("grammar", "sentence", "passage"))
    if not (ok_modes or has_any):
        msgs.append("modes ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” grammar/sentence/passage ì¤‘ 1ê°œ ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
    return (len(msgs) == 0), msgs

def _save_yaml_local(yaml_text: str) -> Path:
    root = Path(effective_persist_dir()).expanduser()
    root.mkdir(parents=True, exist_ok=True)
    p = root / "prompts.yaml"
    p.write_text(yaml_text, encoding="utf-8")
    return p

def _gh_dispatch_workflow(*, owner: str, repo: str, workflow: str, ref: str, token: str, yaml_text: str) -> Dict[str, Any]:
    url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow}/dispatches"
    headers = {"Accept": "application/vnd.github+json", "Authorization": f"Bearer {token}"}
    payload = {"ref": ref, "inputs": {"prompts_yaml": yaml_text}}
    r = req.post(url, headers=headers, json=payload, timeout=15)
    try:
        js = r.json() if r.content else {}
    except Exception:
        js = {}
    if not (200 <= r.status_code < 300):
        raise RuntimeError(f"workflow dispatch ì‹¤íŒ¨(status={r.status_code}): {js or r.text}")
    return {"status": r.status_code, "detail": js or "ok"}

# ---- Page Main ---------------------------------------------------------------
def main() -> None:
    render_sidebar()
    _apply_pending_prefill()

    ok = st.session_state.pop("_flash_success", None)
    er = st.session_state.pop("_flash_error",   None)
    if ok: st.success(ok)
    if er: st.error(er)

    # ìƒíƒœ ë°•ìŠ¤
    with st.container(border=True):
        st.subheader("ğŸ” ìƒíƒœ ì ê²€", divider="gray")
        rp = _resolve_release_prompts_file()
        if rp: st.success(f"ê²½ë¡œ OK â€” prompts.yaml í™•ì¸: {rp}")
        else:  st.warning("prompts.yamlì„ release/assets ë˜ëŠ” ë£¨íŠ¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # í¸ì§‘ UI â€” ì„¸ë¡œ ë°°ì—´(ê°€ë¡œ ì»¬ëŸ¼ ì œê±°)
    st.markdown("### â‘  í˜ë¥´ì†Œë‚˜(ê³µí†µ)")
    st.text_area("ëª¨ë“  ëª¨ë“œì— ê³µí†µ ì ìš©", key=K_PERSONA, height=160, placeholder="í˜ë¥´ì†Œë‚˜ í…ìŠ¤íŠ¸...")

    st.markdown("### â‘¡ ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸(ì§€ì‹œ/ê·œì¹™)")
    st.text_area("ë¬¸ë²•(Grammar) í”„ë¡¬í”„íŠ¸",  key=K_GRAMMAR,  height=220, placeholder="ë¬¸ë²• ëª¨ë“œ ì§€ì‹œ/ê·œì¹™...")
    st.text_area("ë¬¸ì¥(Sentence) í”„ë¡¬í”„íŠ¸", key=K_SENTENCE, height=220, placeholder="ë¬¸ì¥ ëª¨ë“œ ì§€ì‹œ/ê·œì¹™...")
    st.text_area("ì§€ë¬¸(Passage) í”„ë¡¬í”„íŠ¸",  key=K_PASSAGE,  height=220, placeholder="ì§€ë¬¸ ëª¨ë“œ ì§€ì‹œ/ê·œì¹™...")

    # ì•¡ì…˜
    st.markdown("### â‘¢ ì•¡ì…˜")
    b1, b2, b3, b4 = st.columns(4)

    # (a) ìµœì‹  í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°(ë¦´ë¦¬ìŠ¤)
    with b1:
        if st.button("ğŸ“¥ ìµœì‹  í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°(ë¦´ë¦¬ìŠ¤ ìš°ì„ )", use_container_width=True, key="btn_fetch_prompts"):
            try:
                texts, src = _load_prompts_from_release()
                st.session_state["_PREFILL_PROMPTS"] = {
                    K_PERSONA:  texts.get(K_PERSONA, ""),
                    K_GRAMMAR:  texts.get(K_GRAMMAR, ""),
                    K_SENTENCE: texts.get(K_SENTENCE, ""),
                    K_PASSAGE:  texts.get(K_PASSAGE, ""),
                }
                st.session_state["_last_prompts_source"] = str(src)
                st.session_state["_flash_success"] = f"ë¦´ë¦¬ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {src}"
                st.rerun()  # ì½œë°±ì´ ì•„ë‹Œ ì •ìƒ íë¦„ì—ì„œì˜ rerunì´ë¼ ê²½ê³  ì—†ìŒ
            except FileNotFoundError as e:
                st.session_state["_flash_error"] = str(e); st.rerun()
            except Exception:
                st.session_state["_flash_error"] = "í”„ë¡¬í”„íŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."; st.rerun()

    # (b) YAML ë³‘í•©(ë¡œì»¬ í•„ë“œâ†’YAML)
    with b2:
        if st.button("ğŸ§¾ YAML ë³‘í•©(ë¡œì»¬â†’YAML)", use_container_width=True, key="merge_local"):
            st.session_state["_merged_yaml"] = _build_yaml_from_fields()
            st.toast("ë¡œì»¬ í•„ë“œë¥¼ YAMLë¡œ ë³‘í•©í–ˆìŠµë‹ˆë‹¤.", icon="ğŸ§¾")

    # (c) ğŸ’¾ ì—…ë°ì´íŠ¸ ì €ì¥(ë¡œì»¬ persist)
    with b3:
        if st.button("ğŸ’¾ ì—…ë°ì´íŠ¸ ì €ì¥(ë¡œì»¬)", use_container_width=True, key="save_local"):
            y = st.session_state.get("_merged_yaml") or _build_yaml_from_fields()
            okv, msgs = _validate_yaml_text(y)
            if not okv:
                st.error("ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ â€” ë¨¼ì € YAMLì„ ë³‘í•©/ìˆ˜ì •í•˜ì„¸ìš”.")
                if msgs: st.write("\n".join(f"- {m}" for m in msgs))
            else:
                try:
                    p = _save_yaml_local(y)
                    st.success(f"ë¡œì»¬ persistì— ì €ì¥í–ˆìŠµë‹ˆë‹¤: {p}")
                except Exception as exc:
                    st.exception(exc)

    # (d) ğŸš€ ì¶œíŒ(Publish â†’ GitHub Actions dispatch)
    with b4:
        repo_full = st.secrets.get("GITHUB_REPO", "")
        token = st.secrets.get("GITHUB_TOKEN", "")
        ref = st.secrets.get("GITHUB_BRANCH", "main")
        workflow = st.secrets.get("GITHUB_WORKFLOW", "publish-prompts.yml")

        disabled = not (repo_full and "/" in str(repo_full) and token)
        clicked = st.button("ğŸš€ ì¶œíŒ(Publish)", type="primary",
                            disabled=disabled, use_container_width=True,
                            help=None if not disabled else "GITHUB_REPOì™€ GITHUB_TOKEN ì‹œí¬ë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if clicked:
            y = st.session_state.get("_merged_yaml") or _build_yaml_from_fields()
            okv, msgs = _validate_yaml_text(y)
            if not okv:
                st.error("ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ â€” ë¨¼ì € YAMLì„ ë³‘í•©/ìˆ˜ì •í•˜ì„¸ìš”.")
                if msgs: st.write("\n".join(f"- {m}" for m in msgs))
            else:
                try:
                    owner, repo = str(repo_full).split("/", 1)
                    r = _gh_dispatch_workflow(owner=owner, repo=repo, workflow=workflow, ref=ref, token=token, yaml_text=y)
                    st.success("ì¶œíŒ ìš”ì²­ì„ ì „ì†¡í–ˆìŠµë‹ˆë‹¤. Actionsì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.")
                    st.caption(f"status={r.get('status')}, workflow={workflow}, ref={ref}")
                except Exception as exc:
                    st.exception(exc)

    # YAML ë¯¸ë¦¬ë³´ê¸°/í¸ì§‘
    st.markdown("### YAML ë¯¸ë¦¬ë³´ê¸°/í¸ì§‘")
    st.text_area("YAML", key="_merged_yaml", height=320, placeholder="ì—¬ê¸°ì— ë³‘í•©ëœ YAMLì´ í‘œì‹œë©ë‹ˆë‹¤. í•„ìš”í•˜ë©´ ì§ì ‘ ìˆ˜ì •í•˜ì„¸ìš”.")
    if st.session_state.get("_last_prompts_source"):
        st.caption(f"ìµœê·¼ ì†ŒìŠ¤: {st.session_state['_last_prompts_source']}")

if __name__ == "__main__":
    main()
# [AP-KANON-VERT] END
