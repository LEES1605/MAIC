# [01] future import ==========================================================
from __future__ import annotations

# [02] bootstrap & imports ====================================================
import os, io, json, time, traceback, importlib
from pathlib import Path
from typing import Any, Dict, List, Optional

try:
    import streamlit as st
except Exception:
    st = None  # ë¡œì»¬/í…ŒìŠ¤íŠ¸ í™˜ê²½ ë°©ì–´

# [03] secrets â†’ env ìŠ¹ê²© & ì„œë²„ ì•ˆì • ì˜µì…˜ ====================================
def _from_secrets(name: str, default: Optional[str] = None) -> Optional[str]:
    try:
        if st is None or not hasattr(st, "secrets"):
            return os.getenv(name, default)
        val = st.secrets.get(name, None)  # type: ignore[attr-defined]
        if val is None:
            return os.getenv(name, default)
        if isinstance(val, str):
            return val
        return json.dumps(val, ensure_ascii=False)
    except Exception:
        return os.getenv(name, default)

def _bootstrap_env() -> None:
    keys = [
        "OPENAI_API_KEY","OPENAI_MODEL","GEMINI_API_KEY","GEMINI_MODEL",
        "GH_TOKEN","GH_REPO","GH_BRANCH","GH_PROMPTS_PATH",
        "GDRIVE_PREPARED_FOLDER_ID","GDRIVE_BACKUP_FOLDER_ID",
        "APP_MODE","AUTO_START_MODE","LOCK_MODE_FOR_STUDENTS","APP_ADMIN_PASSWORD",
        "DISABLE_BG",
    ]
    for k in keys:
        v = _from_secrets(k)
        if v and not os.getenv(k):
            os.environ[k] = str(v)

    # Streamlit ì•ˆì •í™”
    os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "none")
    os.environ.setdefault("STREAMLIT_RUN_ON_SAVE", "false")
    os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
    os.environ.setdefault("STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION", "false")

_bootstrap_env()

# [04] ê²½ë¡œ/ìƒíƒœ & ì—ëŸ¬ë¡œê·¸ =====================================================
def _persist_dir() -> Path:
    try:
        from src.config import PERSIST_DIR as CFG
        return Path(CFG).expanduser()
    except Exception:
        return Path.home() / ".maic" / "persist"

PERSIST_DIR = _persist_dir()
PERSIST_DIR.mkdir(parents=True, exist_ok=True)

def _is_brain_ready() -> bool:
    p = PERSIST_DIR
    if not p.exists():
        return False
    for s in ["chunks.jsonl","manifest.json",".ready","faiss.index","index.faiss","chroma.sqlite","docstore.json"]:
        fp = p / s
        try:
            if fp.exists() and fp.stat().st_size > 0:
                return True
        except Exception:
            pass
    return False

def _mark_ready() -> None:
    try:
        (PERSIST_DIR / ".ready").write_text("ok", encoding="utf-8")
    except Exception:
        pass

def _errlog(msg: str, *, where: str = "", exc: BaseException | None = None) -> None:
    if st is None:
        return
    ss = st.session_state
    ss.setdefault("_error_log", [])
    ss["_error_log"].append({
        "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
        "where": where,
        "msg": str(msg),
        "trace": traceback.format_exc() if exc else "",
    })

def _errlog_text() -> str:
    if st is None:
        return ""
    out = io.StringIO()
    for i, r in enumerate(st.session_state.get("_error_log", []), 1):
        out.write(f"[{i}] {r['ts']} {r.get('where','')}\n{r['msg']}\n")
        if r.get("trace"):
            out.write(r["trace"] + "\n")
        out.write("-" * 60 + "\n")
    return out.getvalue()

# [05] ì§€ì—° ì„í¬íŠ¸ í—¬í¼ =========================================================
def _try_import(mod: str, attrs: List[str]) -> Dict[str, Any]:
    out: Dict[str, Any] = {}
    try:
        m = importlib.import_module(mod)
    except Exception:
        return out
    for a in attrs:
        try:
            out[a] = getattr(m, a)
        except Exception:
            pass
    return out

# [06] í˜ì´ì§€ ì„¤ì • & í—¤ë”(ì•„ì´ì½˜ ë¡œê·¸ì¸, Enter ì œì¶œ ì§€ì›) =======================
if st:
    st.set_page_config(page_title="LEES AI Teacher", layout="wide")

def _is_admin_view() -> bool:
    env = (os.getenv("APP_MODE") or _from_secrets("APP_MODE", "student") or "student").lower()
    return bool(env == "admin" or (st and (st.session_state.get("is_admin") or st.session_state.get("admin_mode"))))

def _toggle_login_flag():
    st.session_state["_show_admin_login"] = not st.session_state.get("_show_admin_login", False)

def _llm_health_badge() -> tuple[str, str]:
    # ì‹œì‘ ì†ë„ë¥¼ ìœ„í•´ 'í‚¤ ì¡´ì¬'ë§Œìœ¼ë¡œ ìµœì†Œ ìƒíƒœ í‘œì‹œ
    has_g  = bool(os.getenv("GEMINI_API_KEY") or _from_secrets("GEMINI_API_KEY"))
    has_o  = bool(os.getenv("OPENAI_API_KEY") or _from_secrets("OPENAI_API_KEY"))
    if not (has_g or has_o): return ("í‚¤ì—†ìŒ", "âš ï¸")
    if has_g and has_o: return ("Gemini/OpenAI", "âœ…")
    return ("Gemini", "âœ…") if has_g else ("OpenAI", "âœ…")
# START [06A] ìƒíƒœ SSOT í—¬í¼ =========================================
def _get_brain_status() -> dict[str, Any]:
    """í—¤ë”/ê´€ë¦¬ì íŒ¨ë„ì´ ê³µìœ í•˜ëŠ” ë‹¨ì¼ ì§„ì‹¤ ì†ŒìŠ¤(SSOT) ìƒíƒœ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Fields:
      - code: 'READY' | 'SCANNING' | 'RESTORING' | 'WARN' | 'ERROR' | 'MISSING'
      - attached: bool  (Q&A ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€)
      - msg: ì‚¬ìš©ììš© ì§§ì€ ë©”ì‹œì§€
      - source: 'local' | 'drive' | None
    """
    if st is None:
        # headless/test ëª¨ë“œ: íŒŒì¼ì‹œìŠ¤í…œë§Œìœ¼ë¡œ íŒë‹¨
        return {
            "code": "READY" if _is_brain_ready() else "MISSING",
            "attached": bool(_is_brain_ready()),
            "msg": "í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë¡œì»¬ ì¸ë±ìŠ¤ í™•ì¸",
            "source": "local" if _is_brain_ready() else None,
        }

    ss = st.session_state

    # attach/restore íë¦„ì—ì„œ ë¯¸ë¦¬ ê¸°ë¡í•´ ë‘” ìƒíƒœê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    code = (ss.get("brain_status_code") or "").upper().strip()
    msg  = ss.get("brain_status_msg")
    src  = ss.get("brain_source")  # 'local' | 'drive' | None

    # í•˜ìœ„í˜¸í™˜: ì„¸ë¶€ ì½”ë“œê°€ ì—†ë‹¤ë©´ ê¸°ì¡´ ì„¸ì…˜í‚¤ë“¤ë¡œ ìœ ì¶”
    if not code:
        if ss.get("restore_in_progress"):
            code = "RESTORING"
        elif ss.get("scan_in_progress"):
            code = "SCANNING"
        elif ss.get("brain_warning"):
            code = "WARN"
        elif ss.get("brain_error"):
            code = "ERROR"
        else:
            code = "READY" if _is_brain_ready() else "MISSING"

    if not msg:
        default_msgs = {
            "READY": "ë‘ë‡Œ ì¤€ë¹„ì™„ë£Œ",
            "SCANNING": "ìë£Œ ìŠ¤ìº” ì¤‘â€¦",
            "RESTORING": "ë°±ì—… ë³µì› ì¤‘â€¦",
            "WARN": "ì£¼ì˜: ë¶€ë¶„ ë¶ˆì¼ì¹˜/ê²€í†  í•„ìš”",
            "ERROR": "ì˜¤ë¥˜: ë³µêµ¬/ì—°ê²° ì‹¤íŒ¨",
            "MISSING": "ë‘ë‡Œ ì—†ìŒ: ë¹Œë“œ/ë³µì› í•„ìš”",
        }
        msg = default_msgs.get(code, code)

    attached = code in ("READY", "WARN") and _is_brain_ready()

    return {
        "code": code,
        "attached": bool(attached),
        "msg": str(msg),
        "source": src,
    }
# END [06A] ìƒíƒœ SSOT í—¬í¼ =========================================

# START [06] _header êµì²´ (L135â€“L184) =================================
def _header():
    """
    í—¤ë” ë¯¸ë‹ˆë©€:
    - ìƒíƒœ í…ìŠ¤íŠ¸(ì˜ˆ: 'ì¤€ë¹„ì™„ë£Œ') ì œê±°, ì•„ì´ì½˜ë§Œ ì‚¬ìš©
    - ì•„ì´ì½˜ì„ ì œëª© ì•ì— ë°°ì¹˜, ì œëª© í¬ê¸° 1.5ë°°
    - ë¡œê·¸ì¸ íŒì˜¤ë²„ëŠ” ì•ˆì „ í´ë°±(ì§€ì› ì•ˆ ë˜ë©´ expander)
    """
    import streamlit as st
    if st is None:
        return
    ss = st.session_state
    ss.setdefault("_show_admin_login", False)

    status = _get_brain_status()
    code = status["code"]

    # ìƒíƒœ â†’ ì•„ì´ì½˜ë§Œ ì‚¬ìš© (í…ìŠ¤íŠ¸ ì œê±°)
    badge_icon = {
        "READY": "ğŸŸ¢", "SCANNING": "ğŸŸ¡", "RESTORING": "ğŸŸ¡",
        "WARN": "ğŸŸ ", "ERROR": "ğŸ”´", "MISSING": "ğŸ”´",
    }.get(code, "âšª")

    # ê°€ë²¼ìš´ ì•ˆì „ íŒì˜¤ë²„(ë¯¸ì§€ì›/ì‹¤íŒ¨ ì‹œ expander í´ë°±)
    def _safe_popover(label: str, **kw):
        if hasattr(st, "popover"):
            try:
                return st.popover(label, **kw)
            except Exception:
                pass
        return st.expander(label, expanded=True)

    # ì œëª©/ë±ƒì§€ ìŠ¤íƒ€ì¼(ìµœì†Œ CSS)
    st.markdown("""
    <style>
      .brand-row { display:flex; align-items:center; gap:.5rem; }
      .brand-badge { font-size:1.25em; }
      .brand-title { font-size:1.5em; font-weight:800; letter-spacing:.2px; }
    </style>
    """, unsafe_allow_html=True)

    left, right = st.columns([0.78, 0.22])
    with left:
        st.markdown(
            f'<div class="brand-row"><span class="brand-badge">{badge_icon}</span>'
            f'<span class="brand-title">LEES AI Teacher</span></div>',
            unsafe_allow_html=True
        )
    with right:
        # LLM ìƒíƒœ(ê°„ë‹¨ ìº¡ì…˜ë§Œ ìœ ì§€)
        label, icon = _llm_health_badge()
        st.caption(f"LLM: {icon} {label}")

        # ë¡œê·¸ì¸/ë¡œê·¸ì•„ì›ƒ íŒì˜¤ë²„(ì•ˆì „ ë²„ì „)
        if not _is_admin_view():
            with _safe_popover("ğŸ‘¤", use_container_width=True):
                with st.form(key="admin_login"):
                    # ë¹„ë°€ë²ˆí˜¸ í‚¤ í´ë°±: ADMIN_PASSWORD â†’ APP_ADMIN_PASSWORD
                    pwd_set = (_from_secrets("ADMIN_PASSWORD", "")
                               or _from_secrets("APP_ADMIN_PASSWORD", "")
                               or "")
                    pw = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸", type="password")
                    submit = st.form_submit_button("ë¡œê·¸ì¸", use_container_width=True)
                    if submit:
                        if pw and pwd_set and pw == str(pwd_set):
                            ss["admin_mode"] = True
                            st.success("ë¡œê·¸ì¸ ì„±ê³µ")
                            st.rerun()
                        else:
                            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            with _safe_popover("ğŸ‘¤", use_container_width=True):
                with st.form(key="admin_logout"):
                    col1, col2 = st.columns(2)
                    with col1:
                        submit = st.form_submit_button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True)
                    with col2:
                        close  = st.form_submit_button("ë‹«ê¸°",   use_container_width=True)
                if submit:
                    ss["admin_mode"] = False
                    st.success("ë¡œê·¸ì•„ì›ƒ")
                    st.rerun()
                elif close:
                    st.rerun()

    st.divider()
def _login_panel_if_needed():
    return  # ë” ì´ìƒ ì‚¬ìš© ì•ˆ í•¨

# [06B] ë°°ê²½ ë¼ì´ë¸ŒëŸ¬ë¦¬(í•„ìš” ì‹œ) ==============================================
# START [06B] ë°°ê²½ ì™„ì „ ë¹„í™œì„± êµì²´ (L262â€“L345)
def _inject_modern_bg_lib():
    """
    ë°°ê²½ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì£¼ì…ì„ ì™„ì „ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.
    - ê³¼ê±°: ëŒ€ëŸ‰ CSS/JSë¥¼ st.markdown(unsafe_allow_html=True)ë¡œ ì‚½ì…
    - í˜„ì¬: No-Op ì²˜ë¦¬(ì•„ë¬´ ê²ƒë„ í•˜ì§€ ì•ŠìŒ)
    """
    try:
        # í˜¹ì‹œ ì´ì „ ì„¸ì…˜í‚¤ë¥¼ ì‚¬ìš©í•˜ë˜ ì½”ë“œê°€ ìˆì–´ë„ ë¶€ì‘ìš©ì´ ì—†ë„ë¡ Falseë¡œ í†µì¼
        st = globals().get("st", None)
        if st is not None and hasattr(st, "session_state"):
            st.session_state["__bg_lib_injected__"] = False
    except Exception:
        pass

def _mount_background(
    *, theme: str = "light", accent: str = "#5B8CFF", density: int = 3,
    interactive: bool = True, animate: bool = True, gradient: str = "radial",
    grid: bool = True, grain: bool = False, blur: int = 0, seed: int = 1234,
    readability_veil: bool = True,
) -> None:
    """
    ë°°ê²½ì„ ë Œë”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤(í•˜ë“œ OFF).
    - í˜¸ì¶œë¶€(_render_body) êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ë™ì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ ì¦‰ì‹œ return.
    """
    return
# END [06B] ë°°ê²½ ì™„ì „ ë¹„í™œì„± êµì²´ (L262â€“L345)


# [07] ë¶€íŒ…/ì¸ë±ìŠ¤ ì¤€ë¹„(ë¹ ë¥¸ ê²½ë¡œ) =============================================
def _set_brain_status(code: str, msg: str, source: str = "", attached: bool = False):
    """ì„¸ì…˜ ìƒíƒœë¥¼ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì„¸íŒ…í•œë‹¤."""
    ss = st.session_state
    ss["index_status_code"] = code
    ss["brain_status_msg"]  = msg
    ss["index_source"]      = source
    ss["brain_attached"]    = bool(attached)
    ss["restore_recommend"] = (code in ("MISSING","ERROR"))
    ss.setdefault("index_decision_needed", False)
    ss.setdefault("index_change_stats", {})

def _quick_local_attach_only():
    """ë¹ ë¥¸ ë¶€íŒ…: ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ ì—†ì´ ë¡œì»¬ ì‹œê·¸ë„ë§Œ í™•ì¸."""
    ss = st.session_state
    man    = (PERSIST_DIR / "manifest.json")
    chunks = (PERSIST_DIR / "chunks.jsonl")
    ready  = (PERSIST_DIR / ".ready")

    if (chunks.exists() and chunks.stat().st_size > 0) or (man.exists() and man.stat().st_size > 0) or ready.exists():
        _set_brain_status("READY", "ë¡œì»¬ ì¸ë±ìŠ¤ ì—°ê²°ë¨(ë¹ ë¥¸ ë¶€íŒ…)", "local", attached=True)
        return True
    else:
        _set_brain_status("MISSING", "ì¸ë±ìŠ¤ ì—†ìŒ(ê´€ë¦¬ìì—ì„œ 'ê¹Šì€ ì ê²€' í•„ìš”)", "", attached=False)
        return False

def _run_deep_check_and_attach():
    """ê´€ë¦¬ì ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ê²€ì‚¬+ë³µêµ¬."""
    ss = st.session_state
    idx = _try_import("src.rag.index_build", ["quick_precheck", "diff_with_manifest"])
    rel = _try_import("src.backup.github_release", ["restore_latest"])
    quick  = idx.get("quick_precheck")
    diff   = idx.get("diff_with_manifest")
    restore_latest = rel.get("restore_latest")

    # 0) ë¡œì»¬ ë¨¼ì €
    if _is_brain_ready():
        stats = {}
        changed = False
        if callable(diff):
            try:
                d = diff() or {}
                stats = d.get("stats") or {}
                total = int(stats.get("added",0))+int(stats.get("changed",0))+int(stats.get("removed",0))
                changed = total > 0
            except Exception as e:
                _errlog(f"diff ì‹¤íŒ¨: {e}", where="[deep_check]")
        msg = "ë¡œì»¬ ì¸ë±ìŠ¤ ì—°ê²°ë¨" + ("(ì‹ ê·œ/ë³€ê²½ ê°ì§€)" if changed else "(ë³€ê²½ ì—†ìŒ/íŒë‹¨ ë¶ˆê°€)")
        _set_brain_status("READY", msg, "local", attached=True)
        ss["index_decision_needed"] = changed
        ss["index_change_stats"] = stats
        return

    # 1) Drive precheck (ì„ íƒì )
    if callable(quick):
        try: _ = quick() or {}
        except Exception as e: _errlog(f"precheck ì˜ˆì™¸: {e}", where="[deep_check]")

    # 2) GitHub Releases ë³µêµ¬
    restored = False
    if callable(restore_latest):
        try: restored = bool(restore_latest(PERSIST_DIR))
        except Exception as e: _errlog(f"restore ì‹¤íŒ¨: {e}", where="[deep_check]")

    if restored and _is_brain_ready():
        stats = {}
        changed = False
        if callable(diff):
            try:
                d = diff() or {}
                stats = d.get("stats") or {}
                total = int(stats.get("added",0))+int(stats.get("changed",0))+int(stats.get("removed",0))
                changed = total > 0
            except Exception as e:
                _errlog(f"diff ì‹¤íŒ¨(ë³µêµ¬í›„): {e}", where="[deep_check]")
        msg = "Releasesì—ì„œ ë³µêµ¬Â·ì—°ê²°" + ("(ì‹ ê·œ/ë³€ê²½ ê°ì§€)" if changed else "(ë³€ê²½ ì—†ìŒ/íŒë‹¨ ë¶ˆê°€)")
        _set_brain_status("READY", msg, "release", attached=True)
        ss["index_decision_needed"] = changed
        ss["index_change_stats"] = stats
        return

    # 3) ì‹¤íŒ¨
    _set_brain_status("MISSING", "ê¹Šì€ ì ê²€ ì‹¤íŒ¨(ì¸ë±ìŠ¤ ì—†ìŒ). ê´€ë¦¬ì: ì¬ë¹Œë“œ/ë³µêµ¬ í•„ìš”", "", attached=False)
    ss["index_decision_needed"] = False
    ss["index_change_stats"] = {}

# [08] ìë™ ì‹œì‘(ì„ íƒ) â€” ê¸°ë³¸ ë¹„í™œì„± ==========================================
def _auto_start_once():
    """AUTO_START_MODEì— ë”°ë¥¸ 1íšŒì„± ìë™ ë³µì›."""
    if st is None or st.session_state.get("_auto_started"):
        return
    st.session_state["_auto_started"] = True

    if _is_brain_ready():
        return

    mode = (os.getenv("AUTO_START_MODE") or _from_secrets("AUTO_START_MODE", "off") or "off").lower()
    if mode in ("restore","on"):
        rel = _try_import("src.backup.github_release", ["restore_latest"])
        fn = rel.get("restore_latest")
        if not callable(fn): return
        try:
            if fn(dest_dir=PERSIST_DIR):
                _mark_ready()
                st.toast("ìë™ ë³µì› ì™„ë£Œ", icon="âœ…")
                _set_brain_status("READY", "ìë™ ë³µì› ì™„ë£Œ", "release", attached=True)
                # rerunì€ ë‹¨ 1íšŒë§Œ í—ˆìš©
                if not st.session_state.get("_auto_rerun_done"):
                    st.session_state["_auto_rerun_done"] = True
                    st.rerun()
        except Exception as e:
            _errlog(f"auto restore failed: {e}", where="[auto_start]", exc=e)
# [08] END

# ============================== [09] ê´€ë¦¬ì íŒ¨ë„ â€” START ==============================
def _render_admin_panels() -> None:
    """
    ê´€ë¦¬ì íŒ¨ë„(ì§€ì—° ì„í¬íŠ¸ ë²„ì „)
    - í† ê¸€(ë˜ëŠ” ì²´í¬ë°•ìŠ¤)ì„ ì¼  'ì´í›„'ì—ë§Œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ëª¨ë“ˆì„ import ë° ë Œë”í•©ë‹ˆë‹¤.
    - í† ê¸€ì´ êº¼ì ¸ ìˆìœ¼ë©´ ì–´ë–¤ ë¬´ê±°ìš´ ì˜ì¡´ì„±ë„ ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ë©”ì‹œì§€(ê°„ë‹¨) + ìƒì„¸ ìŠ¤íƒ(Expander)ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.
    """
    # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬(ê°€ë²¼ì›€)
    import time
    import importlib
    import traceback

    # ìŠ¤íŠ¸ë¦¼ë¦¿
    import streamlit as st

    st.subheader("ê´€ë¦¬ì íŒ¨ë„")

    # --- (A) í† ê¸€ UI: st.toggle ë¯¸ì§€ì› í™˜ê²½ ëŒ€ë¹„ ì²´í¬ë°•ìŠ¤ í´ë°± ---
    #   - ì„¸ì…˜ ìƒíƒœ í‚¤ë¥¼ ê³ ì •í•´ ì¬ì‹¤í–‰(rerun) ì‹œì—ë„ ìƒíƒœ ìœ ì§€
    toggle_key = "admin_orchestrator_open"
    if toggle_key not in st.session_state:
        st.session_state[toggle_key] = False

    try:
        open_panel = st.toggle(
            "ğŸ”§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë„êµ¬ ì—´ê¸° (ì§€ì—° ë¡œë“œ)",
            value=st.session_state[toggle_key],
            help="í´ë¦­ ì‹œ í•„ìš”í•œ ëª¨ë“ˆì„ ì¦‰ì‹œ ë¡œë“œí•©ë‹ˆë‹¤."
        )
    except Exception:
        open_panel = st.checkbox(
            "ğŸ”§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë„êµ¬ ì—´ê¸° (ì§€ì—° ë¡œë“œ)",
            value=st.session_state[toggle_key],
            help="í´ë¦­ ì‹œ í•„ìš”í•œ ëª¨ë“ˆì„ ì¦‰ì‹œ ë¡œë“œí•©ë‹ˆë‹¤."
        )

    # ì„¸ì…˜ ìƒíƒœ ë™ê¸°í™”
    st.session_state[toggle_key] = bool(open_panel)

    # í† ê¸€ì´ êº¼ì ¸ ìˆìœ¼ë©´, ì–´ë–¤ ë¬´ê±°ìš´ ê²ƒë„ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì¢…ë£Œ
    if not open_panel:
        st.caption("â–¶ í•„ìš”í•  ë•Œë§Œ ë¡œë“œë˜ë„ë¡ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ í† ê¸€ì„ ì¼œë©´ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        return

    load_start = time.perf_counter()
    with st.spinner("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
        mod = None
        last_err = None

        # --- (B) ì§€ì—° ì„í¬íŠ¸ ---
        # í”„ë¡œì íŠ¸ êµ¬ì¡° ë³€í™”ì— ëŒ€ë¹„í•´ ë‘ ê°€ì§€ ê²½ë¡œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
        for module_name in ("src.ui_orchestrator", "ui_orchestrator"):
            try:
                mod = importlib.import_module(module_name)
                break  # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ
            except Exception as e:
                last_err = e
                mod = None

    # ì„í¬íŠ¸ ì‹¤íŒ¨ ì²˜ë¦¬
    if mod is None:
        import textwrap
        st.error("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        if last_err is not None:
            with st.expander("ì˜¤ë¥˜ ìì„¸íˆ ë³´ê¸°"):
                st.code("".join(traceback.format_exception(type(last_err), last_err, last_err.__traceback__)))
        st.info(textwrap.dedent("""
            ì ê²€ íŒ:
            1) ëª¨ë“ˆ ê²½ë¡œê°€ ë§ëŠ”ì§€ í™•ì¸: src/ui_orchestrator.py ë˜ëŠ” ui_orchestrator.py
            2) ëª¨ë“ˆ ë‚´ ì˜ì¡´ íŒ¨í‚¤ì§€ê°€ ëˆ„ë½ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
            3) ëª¨ë“ˆ import ì‹œ ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”ê°€ ê³¼ë„í•˜ì§€ ì•Šì€ì§€ í™•ì¸
        """).strip())
        return

    # --- (C) ë Œë” í•¨ìˆ˜ íƒìƒ‰ ---
    candidate_names = (
        "render_index_orchestrator_panel",
        "render_orchestrator_panel",
        "render",
    )
    render_fn = None
    for fn_name in candidate_names:
        fn = getattr(mod, fn_name, None)
        if callable(fn):
            render_fn = fn
            break

    if render_fn is None:
        st.warning(f"ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë Œë” í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(candidate_names)}")
        return

    # --- (D) ë Œë” ì‹¤í–‰(ì•ˆì „ í˜¸ì¶œ) ---
    try:
        render_fn()  # ëª¨ë“ˆ ì¸¡ì—ì„œ Streamlit ì»´í¬ë„ŒíŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    except Exception as e:
        st.error("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ì˜¤ë¥˜ ìì„¸íˆ ë³´ê¸°"):
            st.code("".join(traceback.format_exception(type(e), e, e.__traceback__)))
        return
    finally:
        elapsed_ms = (time.perf_counter() - load_start) * 1000.0

    st.caption(f"âœ“ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë¡œë“œ/ë Œë” ì™„ë£Œ â€” {elapsed_ms:.0f} ms")

# =============================== [09] ê´€ë¦¬ì íŒ¨ë„ â€” END ===============================


# [10] í•™ìƒ UI (Stable Chatbot): íŒŒìŠ¤í…” ë°°ê²½ + ë§í’ì„  + ìŠ¤íŠ¸ë¦¬ë° =================
def _inject_chat_styles_once():
    """
    ì±„íŒ…ìš© ì „ì—­ CSS 1íšŒ ì£¼ì…:
    - ì»¤ìŠ¤í…€ ë ˆì´ì•„ì›ƒ(.row/.bubble)ê³¼ Streamlit chat ëª¨ë‘ë¥¼ íƒ€ê²ŸíŒ…
    - ì‚¬ìš©ì: ë³´ë¼ í†¤ / AI: í™”ì´íŠ¸, í™•ì‹¤í•œ ëŒ€ë¹„
    """
    import streamlit as st  # ì•ˆì „ìƒ ì¬ì„í¬íŠ¸ í—ˆìš©
    if st.session_state.get("_chat_styles_injected"):
        return
    st.session_state["_chat_styles_injected"] = True

    st.markdown("""
    <style>
      /* ===== ê³µí†µ ì»¨í…Œì´ë„ˆ(ìˆìœ¼ë©´ ì ìš©, ì—†ìœ¼ë©´ ë¬´í•´) ===== */
      .chat-wrap{
        background:#f5f7fb !important;border:1px solid #e6ecf5 !important;border-radius:18px;
        padding:10px 10px 8px;margin-top:10px
      }
      .chat-box{min-height:240px;max-height:54vh;overflow-y:auto;padding:6px 6px 2px}

      /* ===== ì»¤ìŠ¤í…€ ë§í’ì„ (ì•± ë‚´ .row/.bubble êµ¬ì¡°ìš©) ===== */
      .row{display:flex;margin:8px 0}
      .row.user{justify-content:flex-end}
      .row.ai{justify-content:flex-start}
      .bubble{
        max-width:88%;padding:12px 14px;border-radius:16px;line-height:1.6;font-size:15px;
        box-shadow:0 1px 1px rgba(0,0,0,.05);white-space:pre-wrap;position:relative;border:1px solid #e0e4ea;
      }
      /* ì‚¬ìš©ì(ë³´ë¼ í†¤) */
      .bubble.user{
        background:#EFE6FF !important;
        color:#201547;
        border-color:#D6CCFF !important;
        border-top-right-radius:8px;
      }
      /* AI(í™”ì´íŠ¸) */
      .bubble.ai{
        background:#FFFFFF;
        color:#14121f;
        border-top-left-radius:8px;
      }

      /* ===== Streamlit chat ê¸°ë³¸ ìœ„ì ¯ì— ëŒ€í•œ ë³´ì •(ìˆì„ ë•Œë§Œ ì ìš©) ===== */
      /* ì‚¬ìš©ì ë©”ì‹œì§€(ì˜¤ë¥¸ìª½) */
      [data-testid="stChatMessageUser"] > div{
        display:flex; justify-content:flex-end;
      }
      [data-testid="stChatMessageUser"] [data-testid="stMarkdownContainer"]{
        max-width:88%; background:#EFE6FF; color:#201547;
        border:1px solid #D6CCFF; border-radius:16px; border-top-right-radius:8px;
        padding:12px 14px; box-shadow:0 1px 1px rgba(0,0,0,.05);
      }
      /* ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€(ì™¼ìª½) */
      [data-testid="stChatMessage"] > div{
        display:flex; justify-content:flex-start;
      }
      [data-testid="stChatMessage"] [data-testid="stMarkdownContainer"]{
        max-width:88%; background:#FFFFFF; color:#14121f;
        border:1px solid #e0e4ea; border-radius:16px; border-top-left-radius:8px;
        padding:12px 14px; box-shadow:0 1px 1px rgba(0,0,0,.05);
      }

      /* ===== ë¼ë””ì˜¤(ëª¨ë“œ ì„ íƒ) pill í˜•íƒœ ë³´ì • ===== */
      div[data-testid="stRadio"] > div[role="radiogroup"]{display:flex;gap:10px;flex-wrap:wrap}
      div[data-testid="stRadio"] [role="radio"]{
        border:2px solid #bcdcff;border-radius:12px;padding:6px 12px;background:#fff;color:#0a2540;
        font-weight:700;font-size:14px;line-height:1;
      }
      div[data-testid="stRadio"] [role="radio"][aria-checked="true"]{
        background:#eaf6ff;border-color:#9fd1ff;color:#0a2540;
      }
      div[data-testid="stRadio"] svg{display:none!important}
    </style>
    """, unsafe_allow_html=True)
def _render_bubble(role:str, text:str):
    import html, re
    klass = "user" if role=="user" else "ai"
    t = html.escape(text or "").replace("\n","<br/>")
    t = re.sub(r"  ","&nbsp;&nbsp;", t)
    st.markdown(f'<div class="row {klass}"><div class="bubble {klass}">{t}</div></div>', unsafe_allow_html=True)

def _render_mode_controls_pills():
    """
    ì§ˆë¬¸ ëª¨ë“œ ë¼ë””ì˜¤: ë¼ë²¨ ë¬¸êµ¬ë¥¼ ë¯¸ë‹ˆë©€í•˜ê²Œ ìˆ¨ê¹€(label_visibility='collapsed')
    ê¸°ì¡´ ìƒíƒœ í‚¤(ss['qa_mode_radio'])ì™€ 'ì–´ë²•/ë¬¸ì¥/ì§€ë¬¸' ë§µí•‘ ìœ ì§€
    """
    import streamlit as st
    _inject_chat_styles_once()
    ss = st.session_state

    cur = ss.get("qa_mode_radio") or "ë¬¸ë²•"
    labels = ["ì–´ë²•", "ë¬¸ì¥", "ì§€ë¬¸"]
    map_to = {"ì–´ë²•": "ë¬¸ë²•", "ë¬¸ì¥": "ë¬¸ì¥", "ì§€ë¬¸": "ì§€ë¬¸"}
    idx = labels.index({"ë¬¸ë²•": "ì–´ë²•", "ë¬¸ì¥": "ë¬¸ì¥", "ì§€ë¬¸": "ì§€ë¬¸"}[cur])

    # âš ï¸ ë¼ë²¨ ìˆ¨ê¹€(ë¯¸ë‹ˆë©€): label_visibility="collapsed"
    sel = st.radio(
        "ì§ˆë¬¸ ëª¨ë“œ ì„ íƒ",
        options=labels,
        index=idx,
        horizontal=True,
        label_visibility="collapsed",
    )
    new_key = map_to[sel]
    if new_key != cur:
        ss["qa_mode_radio"] = new_key
        st.rerun()
    return ss.get("qa_mode_radio", new_key)
def _render_llm_status_minimal():
    has_g  = bool(os.getenv("GEMINI_API_KEY") or _from_secrets("GEMINI_API_KEY"))
    has_o  = bool(os.getenv("OPENAI_API_KEY") or _from_secrets("OPENAI_API_KEY"))
    ok = bool(has_g or has_o)
    st.markdown(
        f'<span class="status-btn {"green" if ok else "yellow"}">'
        f'{"ğŸŸ¢ ì¤€ë¹„ì™„ë£Œ" if ok else "ğŸŸ¡ í‚¤ì—†ìŒ"}</span>', unsafe_allow_html=True)

def _render_chat_panel():
    import time, base64, json, urllib.request
    try:
        import yaml
    except Exception:
        yaml = None

    ss = st.session_state
    if "chat" not in ss: ss["chat"] = []

    _inject_chat_styles_once()
    _render_llm_status_minimal()
    cur_label = _render_mode_controls_pills()     # "ë¬¸ë²•" / "ë¬¸ì¥" / "ì§€ë¬¸"
    MODE_TOKEN = {"ë¬¸ë²•":"ë¬¸ë²•ì„¤ëª…","ë¬¸ì¥":"ë¬¸ì¥êµ¬ì¡°ë¶„ì„","ì§€ë¬¸":"ì§€ë¬¸ë¶„ì„"}[cur_label]

    ev_notes  = ss.get("__evidence_class_notes", "")
    ev_books  = ss.get("__evidence_grammar_books", "")

    # GitHub prompts ë¡œë”(ì§ˆë¬¸ì´ ìˆì„ ë•Œë§Œ ë„¤íŠ¸ì›Œí¬)
    def _github_fetch_prompts_text():
        token  = st.secrets.get("GH_TOKEN") or os.getenv("GH_TOKEN")
        repo   = st.secrets.get("GH_REPO")  or os.getenv("GH_REPO")
        branch = st.secrets.get("GH_BRANCH", "main") or os.getenv("GH_BRANCH","main")
        path   = st.secrets.get("GH_PROMPTS_PATH", "prompts.yaml") or os.getenv("GH_PROMPTS_PATH","prompts.yaml")
        if not (token and repo and yaml):
            return None
        url = f"https://api.github.com/repos/{repo}/contents/{path}?ref={branch}"
        req = urllib.request.Request(url, headers={"Authorization": f"token {token}","User-Agent": "maic-app"})
        try:
            with urllib.request.urlopen(req) as r:
                meta = json.loads(r.read().decode("utf-8"))
                content_b64 = meta.get("content") or ""
                text = base64.b64decode(content_b64.encode("utf-8")).decode("utf-8")
                ss["__gh_prompts_cache"] = {"sha": meta.get("sha"), "text": text}
                return text
        except Exception:
            return None

    def _build_prompt_from_github(mode_token: str, q: str, ev1: str, ev2: str):
        txt = _github_fetch_prompts_text()
        if not (txt and yaml): return None
        try:
            data = yaml.safe_load(txt) or {}
            node = (data.get("modes") or {}).get(mode_token)
            if not node: return None
            sys_p = node.get("system") if isinstance(node, dict) else None
            usr_p = node.get("user")   if isinstance(node, dict) else (node if isinstance(node, str) else None)
            if usr_p is None: return None
            usr_p = (usr_p
                     .replace("{QUESTION}", q)
                     .replace("{EVIDENCE_CLASS_NOTES}", ev1 or "")
                     .replace("{EVIDENCE_GRAMMAR_BOOKS}", ev2 or ""))
            return {"system": sys_p, "user": usr_p}
        except Exception:
            return None

    def _build_prompt_from_drive(mode_token: str, q: str, ev1: str, ev2: str):
        _prompt_mod = _try_import("src.prompt_modes", ["build_prompt"]) or {}
        fn = _prompt_mod.get("build_prompt")
        if not callable(fn): return None
        try:
            parts = fn(mode_token, q) or {}
            sys_p = parts.get("system")
            usr_p = parts.get("user")
            if usr_p:
                usr_p = (usr_p
                         .replace("{QUESTION}", q)
                         .replace("{EVIDENCE_CLASS_NOTES}", ev1 or "")
                         .replace("{EVIDENCE_GRAMMAR_BOOKS}", ev2 or ""))
            return {"system": sys_p, "user": usr_p}
        except Exception:
            return None

    def _fallback_prompts(mode_token: str, q: str, ev1: str, ev2: str, cur_label: str):
        NOTICE = "ì•ˆë‚´: í˜„ì¬ ìë£Œ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ ê°„ë‹¨ ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤. í•µì‹¬ë§Œ ì§§ê²Œ ì•ˆë‚´í• ê²Œìš”."
        BASE = "ë„ˆëŠ” í•œêµ­ì˜ ì˜ì–´í•™ì› ì›ì¥ì²˜ëŸ¼ ë”°ëœ»í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•œë‹¤. ëª¨ë“  ì¶œë ¥ì€ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ."
        if mode_token == "ë¬¸ë²•ì„¤ëª…":
            sys_p = BASE + " ì£¼ì œì—ì„œ ë²—ì–´ë‚œ ì¥í™©í•œ ë°°ê²½ì„¤ëª…ì€ ê¸ˆì§€í•œë‹¤."
            lines = []
            if not ev1 and not ev2: lines.append(NOTICE)
            lines += [
                "1) í•œ ì¤„ í•µì‹¬",
                "2) ì´ë¯¸ì§€/ë¹„ìœ  (ì§§ê²Œ)",
                "3) í•µì‹¬ ê·œì¹™ 3â€“5ê°œ (â€¢ bullet)",
                "4) ì˜ˆë¬¸ 1ê°œ(+í•œêµ­ì–´ í•´ì„)",
                "5) í•œ ë¬¸ì¥ ë¦¬ë§ˆì¸ë“œ",
                "6) ì¶œì²˜ 1ê°œ: [ì¶œì²˜: ì´ìœ ë¬¸ë²•] / [ì¶œì²˜: ì±…ì œëª©(â€¦)] / [ì¶œì²˜: AIìì²´ì§€ì‹]",
            ]
            usr_p = f"[ì§ˆë¬¸]\n{q}\n\n[ì‘ì„± ì§€ì¹¨]\n- í˜•ì‹ì„ ì§€ì¼œë¼.\n" + "\n".join(f"- {x}" for x in lines)
        elif mode_token == "ë¬¸ì¥êµ¬ì¡°ë¶„ì„":
            sys_p = BASE + " ë¶ˆí™•ì‹¤í•œ íŒë‹¨ì€ 'ì•½ ~% ë¶ˆí™•ì‹¤'ë¡œ ëª…ì‹œí•œë‹¤."
            usr_p = (
                "[ì¶œë ¥ í˜•ì‹]\n"
                "0) ëª¨í˜¸ì„± ì ê²€\n"
                "1) ê´„í˜¸ ê·œì¹™ ìš”ì•½\n"
                "2) í•µì‹¬ ê³¨ê²© Sâ€“Vâ€“Oâ€“Câ€“M í•œ ì¤„ ê°œìš”\n"
                "3) ì„±ë¶„ ì‹ë³„: í‘œ/ë¦¬ìŠ¤íŠ¸\n"
                "4) êµ¬ì¡°/êµ¬ë¬¸: ìˆ˜ì‹ ê´€ê³„Â·It-cleftÂ·ê°€ì£¼ì–´/ì§„ì£¼ì–´Â·ìƒëµ ë³µì› ë“± ë‹¨ê³„ì  ì„¤ëª…\n"
                "5) í•µì‹¬ í¬ì¸íŠ¸ 2â€“3ê°œ\n"
                "6) ì¶œì²˜(ë³´ìˆ˜): [ê·œì¹™/ìë£Œ/ìˆ˜ì—…ë…¸íŠ¸ ë“± â€˜ì¶œì²˜ ìœ í˜•â€™ë§Œ]\n\n"
                f"[ë¬¸ì¥]\n{q}"
            )
        else:
            sys_p = BASE + " ë¶ˆí™•ì‹¤í•œ íŒë‹¨ì€ 'ì•½ ~% ë¶ˆí™•ì‹¤'ë¡œ ëª…ì‹œí•œë‹¤."
            usr_p = (
                "[ì¶œë ¥ í˜•ì‹]\n"
                "1) í•œ ì¤„ ìš”ì§€(ëª…ì‚¬êµ¬)\n"
                "2) êµ¬ì¡° ìš”ì•½: (ì„œë¡ â€“ë³¸ë¡ â€“ê²°ë¡ ) ë˜ëŠ” ë‹¨ë½ë³„ í•µì‹¬ ë¬¸ì¥\n"
                "3) í•µì‹¬ì–´/í‘œí˜„ 3â€“6ê°œ + ì´ìœ \n"
                "4) ë¬¸ì œí’€ì´ íŒíŠ¸(ìˆë‹¤ë©´)\n\n"
                f"[ì§€ë¬¸/ì§ˆë¬¸]\n{q}"
            )
        st.session_state["__prompt_source"] = "Fallback"
        return sys_p, usr_p

    def _resolve_prompts(mode_token: str, q: str, ev1: str, ev2: str, cur_label: str):
        gh = _build_prompt_from_github(mode_token, q, ev1, ev2)
        if gh and (gh.get("system") or gh.get("user")):
            st.session_state["__prompt_source"] = "GitHub"
            sys_p = gh.get("system") or ""
            usr_p = gh.get("user") or f"[ëª¨ë“œ:{mode_token}]\n{q}"
            if mode_token == "ë¬¸ë²•ì„¤ëª…" and not ev1 and not ev2:
                usr_p += "\n\n[ì§€ì‹œ]\n- ë‹µë³€ ì²« ì¤„ì„ ë‹¤ìŒ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘: 'ì•ˆë‚´: í˜„ì¬ ìë£Œ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ ê°„ë‹¨ ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤. í•µì‹¬ë§Œ ì§§ê²Œ ì•ˆë‚´í• ê²Œìš”.'"
            return sys_p, usr_p

        dv = _build_prompt_from_drive(mode_token, q, ev1, ev2)
        if dv and (dv.get("system") or dv.get("user")):
            st.session_state["__prompt_source"] = "Drive"
            sys_p = dv.get("system") or ""
            usr_p = dv.get("user") or f"[ëª¨ë“œ:{mode_token}]\n{q}"
            if mode_token == "ë¬¸ë²•ì„¤ëª…" and not ev1 and not ev2:
                usr_p += "\n\n[ì§€ì‹œ]\n- ë‹µë³€ ì²« ì¤„ì„ ë‹¤ìŒ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘: 'ì•ˆë‚´: í˜„ì¬ ìë£Œ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ ê°„ë‹¨ ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤. í•µì‹¬ë§Œ ì§§ê²Œ ì•ˆë‚´í• ê²Œìš”.'"
            return sys_p, usr_p

        return _fallback_prompts(mode_token, q, ev1, ev2, cur_label)

    # ì…ë ¥ & ë Œë”
    user_q = st.chat_input("ì˜ˆ) ë¶„ì‚¬êµ¬ë¬¸ì´ ë­ì˜ˆìš”?  ì˜ˆ) ì´ ë¬¸ì¥ êµ¬ì¡° ë¶„ì„í•´ì¤˜")
    qtxt = user_q.strip() if user_q and user_q.strip() else None
    do_stream = qtxt is not None
    if do_stream:
        ts = int(time.time()*1000); uid = f"u{ts}"
        ss["chat"].append({"id": uid, "role": "user", "text": qtxt})

    with st.container():
        st.markdown('<div class="chat-wrap"><div class="chat-box">', unsafe_allow_html=True)
        for m in ss["chat"]:
            _render_bubble(m.get("role","assistant"), m.get("text",""))

        text_final = ""
        if do_stream:
            ph = st.empty()
            ph.markdown(f'<div class="row ai"><div class="bubble ai">{"ë‹µë³€ ì¤€ë¹„ì¤‘â€¦"}</div></div>', unsafe_allow_html=True)
            system_prompt, user_prompt = _resolve_prompts(MODE_TOKEN, qtxt, ev_notes, ev_books, cur_label)

            # LLM ì–´ëŒ‘í„°ëŠ” í•„ìš”í•  ë•Œë§Œ ì§€ì—° ì„í¬íŠ¸
            prov = _try_import("src.llm.providers", ["call_with_fallback"])
            call = prov.get("call_with_fallback")

            if not callable(call):
                text_final = "(ì˜¤ë¥˜) LLM ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                ph.markdown(f'<div class="row ai"><div class="bubble ai">{text_final}</div></div>', unsafe_allow_html=True)
            else:
                import inspect
                sig = inspect.signature(call); params = sig.parameters.keys(); kwargs = {}
                if "messages" in params:
                    kwargs["messages"] = [
                        {"role":"system","content":system_prompt or ""},
                        {"role":"user","content":user_prompt},
                    ]
                else:
                    if "prompt" in params: kwargs["prompt"] = user_prompt
                    elif "user_prompt" in params: kwargs["user_prompt"] = user_prompt
                    if "system_prompt" in params: kwargs["system_prompt"] = (system_prompt or "")
                    elif "system" in params:      kwargs["system"] = (system_prompt or "")

                if "mode_token" in params: kwargs["mode_token"] = MODE_TOKEN
                elif "mode" in params:     kwargs["mode"] = MODE_TOKEN
                if "temperature" in params: kwargs["temperature"] = 0.2
                elif "temp" in params:      kwargs["temp"] = 0.2
                if "timeout_s" in params:   kwargs["timeout_s"] = 90
                elif "timeout" in params:   kwargs["timeout"] = 90
                if "extra" in params:       kwargs["extra"] = {"question": qtxt, "mode_key": cur_label}

                acc = ""
                def _emit(piece: str):
                    nonlocal acc
                    acc += str(piece)
                    ph.markdown(f'<div class="row ai"><div class="bubble ai">{acc}</div></div>', unsafe_allow_html=True)

                supports_stream = ("stream" in params) or ("on_token" in params) or ("on_delta" in params) or ("yield_text" in params)
                try:
                    if supports_stream:
                        if "stream" in params:   kwargs["stream"] = True
                        if "on_token" in params: kwargs["on_token"] = _emit
                        if "on_delta" in params: kwargs["on_delta"] = _emit
                        if "yield_text" in params: kwargs["yield_text"] = _emit
                        res = call(**kwargs)
                        text_final = (res.get("text") if isinstance(res, dict) else acc) or acc
                    else:
                        res  = call(**kwargs)
                        text_final = res.get("text") if isinstance(res, dict) else str(res)
                        if not text_final: text_final = "(ì‘ë‹µì´ ë¹„ì–´ìˆì–´ìš”)"
                        ph.markdown(f'<div class="row ai"><div class="bubble ai">{text_final}</div></div>', unsafe_allow_html=True)
                except Exception as e:
                    text_final = f"(ì˜¤ë¥˜) {type(e).__name__}: {e}"
                    ph.markdown(f'<div class="row ai"><div class="bubble ai">{text_final}</div></div>', unsafe_allow_html=True)
                    _errlog(f"LLM ì˜ˆì™¸: {e}", where="[qa_llm]", exc=e)

        st.markdown('</div></div>', unsafe_allow_html=True)

    if do_stream:
        ss["chat"].append({"id": f"a{int(time.time()*1000)}", "role": "assistant", "text": text_final})
        st.rerun()

# [11] ë³¸ë¬¸ ë Œë” ===============================================================
def _render_body() -> None:
    if st is None:
        return

    # ë°°ê²½(í•„ìš” ì‹œ)
    _mount_background(theme="light", accent="#5B8CFF", density=3,
                      interactive=True, animate=True, gradient="radial",
                      grid=True, grain=False, blur=0, seed=1234, readability_veil=True)

    _header()

    # ë¹ ë¥¸ ë¶€íŒ…: ë„¤íŠ¸ì›Œí¬ ì—†ì´ ë¡œì»¬ë§Œ í™•ì¸
    try:
        _quick_local_attach_only()
    except Exception as e:
        _errlog(f"quick attach failed: {e}", where="[render_body]", exc=e)

    # ê´€ë¦¬ì íŒ¨ë„ + ê¹Šì€ ì ê²€ ë²„íŠ¼(ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ)
    if _is_admin_view():
        _render_admin_panels()
        with st.container():
            if st.button(
                "ğŸ” ìë£Œ ìë™ ì ê²€(ê¹Šì€ ê²€ì‚¬)",
                help="Drive/Release ì ê²€ ë° ë³µêµ¬, ë³€ê²½ ê°ì§€ ìˆ˜í–‰",
                use_container_width=True
            ):
                with st.spinner("ê¹Šì€ ì ê²€ ì¤‘â€¦"):
                    _run_deep_check_and_attach()
                    st.success(st.session_state.get("brain_status_msg", "ì™„ë£Œ"))
                    st.rerun()

    _auto_start_once()

    st.markdown("## ì§ˆë¬¸ì€ ì²œì¬ë“¤ì˜ ê³µë¶€ ë°©ë²•ì´ë‹¤.")
    _render_chat_panel()

# [12] main ===================================================================
def main():
    if st is None:
        print("Streamlit í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return
    _render_body()

if __name__ == "__main__":
    main()
# =============================== [END] =======================================
