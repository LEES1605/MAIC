# ==== [01] future import =====================================================
from __future__ import annotations

# ==== [02] bootstrap & imports ==============================================
import os, io, json, time, traceback, importlib
from pathlib import Path
from typing import Any, Dict, List, Optional

try:
    import streamlit as st
except Exception:
    st = None  # ë¡œì»¬/í…ŒìŠ¤íŠ¸ í™˜ê²½ ë°©ì–´

# ==== [03] secrets â†’ env ìŠ¹ê²© & ì„œë²„ ì•ˆì • ì˜µì…˜ ===============================
def _from_secrets(name: str, default: Optional[str] = None) -> Optional[str]:
    try:
        if st is None or not hasattr(st, "secrets"):
            return os.getenv(name, default)
        val = st.secrets.get(name, None)  # type: ignore[attr-defined]
        if val is None:
            return os.getenv(name, default)
        if isinstance(val, str):
            return val
        return json.dumps(val, ensure_ascii=False)
    except Exception:
        return os.getenv(name, default)

def _bootstrap_env() -> None:
    keys = [
        # LLM
        "OPENAI_API_KEY","OPENAI_MODEL","GEMINI_API_KEY","GEMINI_MODEL",
        # GitHub
        "GITHUB_TOKEN","GITHUB_REPO",
        # Drive
        "GDRIVE_PREPARED_FOLDER_ID","GDRIVE_BACKUP_FOLDER_ID",
        # App
        "APP_MODE",          # admin|student
        "AUTO_START_MODE",   # detect|restore|full
    ]
    for k in keys:
        v = _from_secrets(k)
        if v and not os.getenv(k):
            os.environ[k] = str(v)

    # ì„œë²„ ì•ˆì • ì„¤ì •
    os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "none")
    os.environ.setdefault("STREAMLIT_RUN_ON_SAVE", "false")
    os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
    os.environ.setdefault("STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION", "false")

_bootstrap_env()

# ==== [04] ê²½ë¡œ/ìƒíƒœ & ì—ëŸ¬ë¡œê·¸ ==============================================
def _persist_dir() -> Path:
    try:
        from src.config import PERSIST_DIR as CFG  # í”„ë¡œì íŠ¸ í‘œì¤€ ê²½ë¡œ
        return Path(CFG).expanduser()
    except Exception:
        return Path.home() / ".maic" / "persist"

PERSIST_DIR = _persist_dir()
PERSIST_DIR.mkdir(parents=True, exist_ok=True)

def _is_brain_ready() -> bool:
    p = PERSIST_DIR
    if not p.exists(): return False
    signals = ["chunks.jsonl","manifest.json",".ready","faiss.index","index.faiss","chroma.sqlite","docstore.json"]
    for s in signals:
        fp = p / s
        try:
            if fp.exists() and fp.stat().st_size > 0:
                return True
        except Exception:
            pass
    return False

def _mark_ready() -> None:
    try: (PERSIST_DIR / ".ready").write_text("ok", encoding="utf-8")
    except Exception: pass

def _errlog(msg: str, *, where: str = "", exc: BaseException | None = None) -> None:
    if st is None: return
    ss = st.session_state
    ss.setdefault("_error_log", [])
    ss["_error_log"].append({
        "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
        "where": where, "msg": str(msg),
        "trace": traceback.format_exc() if exc else "",
    })

def _errlog_text() -> str:
    if st is None: return ""
    out = io.StringIO()
    for i, r in enumerate(st.session_state.get("_error_log", []), 1):
        out.write(f"[{i}] {r['ts']} {r.get('where','')}\n{r['msg']}\n")
        if r.get("trace"): out.write(r["trace"] + "\n")
        out.write("-"*60 + "\n")
    return out.getvalue()

# ==== [05] ë™ì  ì„í¬íŠ¸ ë°”ì¸ë”©(ìˆëŠ” ê²ƒë§Œ ì‚¬ìš©) ===============================
_import_warns: List[str] = []

def _try_import(mod: str, attrs: List[str]) -> Dict[str, Any]:
    out: Dict[str, Any] = {}
    try:
        m = importlib.import_module(mod)
    except Exception as e:
        _import_warns.append(f"{mod}: {type(e).__name__}: {e}")
        return out
    for a in attrs:
        try:
            out[a] = getattr(m, a)
        except Exception:
            pass
    return out

# ê´€ë¦¬ì/ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°/ë°±ì—…/RAG/LLM
_ui_admin = _try_import("src.ui_admin", [
    "ensure_admin_session_keys", "render_admin_controls", "render_role_caption", "render_mode_radio_admin"
])
_ui_orch  = _try_import("src.ui_orchestrator", ["render_index_orchestrator_panel"])
_gh       = _try_import("src.backup.github_release", ["restore_latest"])
_rag      = _try_import("src.rag.index_build", ["build_index_with_checkpoint"])
_llm      = _try_import("src.llm.providers", ["call_with_fallback","call_openai","call_gemini"])

# ==== [06] í˜ì´ì§€ ì„¤ì • & í—¤ë” =================================================
if st:
    st.set_page_config(page_title="AI Teacher", layout="wide")

def _is_admin_view() -> bool:
    env = (os.getenv("APP_MODE") or _from_secrets("APP_MODE","student") or "student").lower()
    return bool(env == "admin" or (st and (st.session_state.get("is_admin") or st.session_state.get("admin_mode"))))

def _header():
    if st is None: return
    left, right = st.columns([0.7, 0.3])
    with left:
        st.markdown("### AI Teacher")
        st.caption("MAIC Â· Streamlit ê¸°ë°˜ 24/7 Q&A")
    with right:
        st.markdown(f"**{'ğŸŸ¢ ë‘ë‡Œ ì¤€ë¹„ë¨' if _is_brain_ready() else 'ğŸŸ¡ ë‘ë‡Œ ì—°ê²° ëŒ€ê¸°'}**")
        if _import_warns:
            with st.expander("ì„í¬íŠ¸ ê²½ê³ ", expanded=False):
                for w in _import_warns: st.code(w, language="text")
    st.divider()

# ==== [07] ì‹œì‘ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ==============================================
def _auto_start_once() -> None:
    if st is None: return
    if st.session_state.get("_auto_started"): return
    st.session_state["_auto_started"] = True

    if _is_brain_ready():  # ì´ë¯¸ ì¤€ë¹„ë¨
        return

    mode = (os.getenv("AUTO_START_MODE") or _from_secrets("AUTO_START_MODE","detect") or "detect").lower()
    try:
        if mode == "restore" and _gh.get("restore_latest"):
            ok = bool(_gh["restore_latest"](dest_dir=PERSIST_DIR))
            if ok: _mark_ready()
        elif mode == "full" and _rag.get("build_index_with_checkpoint"):
            _rag["build_index_with_checkpoint"](
                update_pct=lambda *_: None, update_msg=lambda *_: None,
                gdrive_folder_id=os.getenv("GDRIVE_PREPARED_FOLDER_ID","prepared"),
                gcp_creds={}, persist_dir=str(PERSIST_DIR), remote_manifest={}
            )
            _mark_ready()
        # detect ëª¨ë“œ: í™”ë©´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ì„œ ì§ˆë¬¸ ì§„í–‰
    except Exception as e:
        _errlog(f"AUTO_START_MODE ì‹¤í–‰ ì˜¤ë¥˜: {e}", where="[auto_start]", exc=e)

# ==== [08] ê´€ë¦¬ì íŒ¨ë„(ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°/ëª¨ë“œ/ë¡œê·¸) ============================
def _render_admin_panels() -> None:
    if st is None or not _is_admin_view(): return

    # ìƒë‹¨ ê³µí†µ ì»¨íŠ¸ë¡¤
    if _ui_admin.get("ensure_admin_session_keys"): _ui_admin["ensure_admin_session_keys"]()
    if _ui_admin.get("render_admin_controls"):     _ui_admin["render_admin_controls"]()
    if _ui_admin.get("render_role_caption"):       _ui_admin["render_role_caption"]()
    st.divider()

    # ìë£Œ/ì¸ë±ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    st.markdown("## ê´€ë¦¬ì: ìë£Œ/ì¸ë±ìŠ¤ ê´€ë¦¬")
    if _ui_orch.get("render_index_orchestrator_panel"):
        _ui_orch["render_index_orchestrator_panel"]()
    else:
        st.info("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤: src.ui_orchestrator")

    # ì„¤ëª… ëª¨ë“œ ë¼ë””ì˜¤(ê´€ë¦¬ì ì „ìš©)
    st.markdown("### ì„¤ëª… ëª¨ë“œ ì„¤ì •")
    if _ui_admin.get("render_mode_radio_admin"):
        _ui_admin["render_mode_radio_admin"]()
    else:
        default = st.session_state.get("qa_mode_radio","ë¬¸ë²•ì„¤ëª…")
        st.session_state["qa_mode_radio"] = st.radio("ì„¤ëª… ëª¨ë“œ", ["ë¬¸ë²•ì„¤ëª…","ë¬¸ì¥êµ¬ì¡°ë¶„ì„","ì§€ë¬¸ë¶„ì„"],
                                                     index=["ë¬¸ë²•ì„¤ëª…","ë¬¸ì¥êµ¬ì¡°ë¶„ì„","ì§€ë¬¸ë¶„ì„"].index(default))

    # ì˜¤ë¥˜ ë¡œê·¸
    with st.expander("ì˜¤ë¥˜ ë¡œê·¸", expanded=False):
        txt = _errlog_text()
        st.text_area("ìµœê·¼ ì˜¤ë¥˜", value=txt, height=180)
        st.download_button("ë¡œê·¸ ë‹¤ìš´ë¡œë“œ", data=txt.encode("utf-8"), file_name="app_error_log.txt")

# ==== [09] ì±„íŒ… íŒ¨ë„(í•™ìƒ/ê´€ë¦¬ì ê³µí†µ) ======================================
def _llm_call(prompt: str, system: Optional[str] = None) -> Dict[str, Any]:
    """
    í†µì¼ LLM í˜¸ì¶œ: Gemini â†’ ì‹¤íŒ¨ ì‹œ OpenAI í´ë°±.
    providers ëª¨ë“ˆì´ ì—†ìœ¼ë©´ ê°„ë‹¨ ì—ëŸ¬ ë°˜í™˜.
    """
    if _llm.get("call_with_fallback"):
        return _llm["call_with_fallback"](prompt=prompt, system=system,
                                          primary="gemini", secondary="openai",
                                          temperature=0.3, max_tokens=800)
    return {"ok": False, "error": "LLM providers ëª¨ë“ˆ ë¯¸íƒ‘ì¬"}

def _render_chat_panel() -> None:
    if st is None: return
    ss = st.session_state
    ss.setdefault("chat", [])
    ss.setdefault("_chat_next_id", 1)
    ready = _is_brain_ready()

    # ìƒë‹¨ ë°°ì§€
    with st.container(border=True):
        left, right = st.columns([0.7, 0.3])
        with left:
            st.markdown(f"**{'ğŸŸ¢ ë‘ë‡Œ ì¤€ë¹„ë¨' if ready else 'ğŸŸ¡ ë‘ë‡Œ ì—°ê²° ëŒ€ê¸°'}**")
        with right:
            mode = ss.get("qa_mode_radio","ë¬¸ë²•ì„¤ëª…")
            st.markdown(f"ëª¨ë“œ: **{mode}**")

    # ëŒ€í™” ì´ë ¥
    with st.container(border=True):
        for m in ss["chat"]:
            if m["role"] == "user":
                with st.chat_message("user", avatar="ğŸ§‘"): st.markdown(m["text"])
            else:
                with st.chat_message("assistant", avatar="ğŸ¤–"): st.markdown(m["text"])

    # ì…ë ¥
    user_q = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if not user_q: return

    msg_id = ss["_chat_next_id"]; ss["_chat_next_id"] += 1
    ss["chat"].append({"id": msg_id, "role":"user", "text": user_q})

    system_prompt = "ë„ˆëŠ” í•œêµ­ì˜ ì˜ì–´í•™ì› ì›ì¥ì²˜ëŸ¼, ë”°ëœ»í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•œë‹¤."
    mode = ss.get("qa_mode_radio","ë¬¸ë²•ì„¤ëª…")
    prompt = f"[ëª¨ë“œ:{mode}]\n{user_q}"

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        slot = st.empty()
        try:
            res = _llm_call(prompt, system_prompt)
            if res.get("ok"):
                text = (res.get("text") or "").strip()
                ss["chat"].append({"id": msg_id+1, "role":"assistant", "text": text, "provider": res.get("provider")})
                slot.markdown(text)
            else:
                slot.error(f"ìƒì„± ì‹¤íŒ¨: {res.get('error')}")
                _errlog(f"LLM ì‹¤íŒ¨: {res.get('error')}", where="[qa_llm]")
        except Exception as e:
            slot.error(f"ì˜ˆì™¸: {type(e).__name__}: {e}")
            _errlog(f"LLM ì˜ˆì™¸: {e}", where="[qa_llm]", exc=e)

# ==== [10] í•™ìƒ/ê´€ë¦¬ì ë·° ê²Œì´íŒ… ============================================
def _render_body() -> None:
    if st is None: return
    # í—¤ë” + ìë™ ì‹œì‘ í›…
    _header()
    _auto_start_once()

    # ê´€ë¦¬ìì—ê²Œë§Œ ê´€ë¦¬ì íŒ¨ë„ ë…¸ì¶œ
    if _is_admin_view():
        _render_admin_panels()

    # Q&AëŠ” ê³µí†µ
    st.markdown("## Q&A")
    _render_chat_panel()

# ==== [11] main ==============================================================
def main():
    if st is None:
        print("Streamlit í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return
    _render_body()

if __name__ == "__main__":
    main()
