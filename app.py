# ===== [01] APP BOOT =========================================================
from __future__ import annotations

import streamlit as st

# RAG ì—”ì§„ì´ ì—†ì–´ë„ ì•±ì´ ì£½ì§€ ì•Šê²Œ try/exceptë¡œ ê°ìŒˆ
try:
    from src.rag_engine import get_or_build_index, LocalIndexMissing
except Exception:
    get_or_build_index = None
    class LocalIndexMissing(Exception):  # ì•ˆì „ ê°€ë“œ
        ...

st.set_page_config(page_title="AI Teacher (Clean)", layout="wide")

# ì¸ë±ìŠ¤ ìƒíƒœë¥¼ ì„¸ì…˜ì— ë³´ê´€ (ì—†ìœ¼ë©´ None)
if "rag_index" not in st.session_state:
    st.session_state["rag_index"] = None

def _index_status_badge() -> None:
    """ì°½ê³  ìƒíƒœ í‘œì‹œ: ì¤€ë¹„/ì—†ìŒ."""
    if st.session_state["rag_index"] is None:
        st.caption("Index status: âŒ missing (ë¹Œë“œ ë˜ëŠ” ë³µêµ¬ í•„ìš”)")
    else:
        st.caption("Index status: âœ… ready")

st.title("ğŸ§‘â€ğŸ« AI Teacher â€” Clean Scaffold")
_index_status_badge()

# ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œë§Œ ë¡œë“œ/ë¹Œë“œ ì‹œë„ (ì—†ìœ¼ë©´ í¬ë˜ì‹œ ëŒ€ì‹  ì•ˆë‚´)
if st.button("Build/Load Index"):
    with st.spinner("Loading / building local indexâ€¦"):
        if get_or_build_index is None:
            st.warning("RAG ì—”ì§„ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        else:
            try:
                idx = get_or_build_index()              # â† ì—¬ê¸°ì„œ ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
                st.session_state["rag_index"] = idx     # ì¤€ë¹„ ì™„ë£Œ ìƒíƒœë¡œ ì €ì¥
                st.success("Index ready.")
            except LocalIndexMissing:
                # ì°½ê³ ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì—¬ê¸°ë¡œ ë–¨ì–´ì§ â€” í¬ë˜ì‹œ ëŒ€ì‹  ì•ˆë‚´ë§Œ.
                st.info("ì•„ì§ ë¡œì»¬ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë°±ì—… ë³µêµ¬ ë˜ëŠ” ì¸ë±ìŠ¤ ë¹Œë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"Index load/build failed: {type(e).__name__}: {e}")
# ===== [02] RAG: Restore / Make Backup (zip â†’ loose â†’ prepared â†’ manual) =====
# ëª©ì :
# 1) BACKUP í´ë”ì— ZIPì´ ìˆìœ¼ë©´: ë‚´ë ¤ë°›ì•„ APP_DATA_DIRì— í’€ê³  ì¸ë±ìŠ¤ ë¡œë“œ
# 2) ZIPì´ ì—†ìœ¼ë©´: BACKUP í´ë” ì•ˆì˜ ëŠìŠ¨í•œ íŒŒì¼(chunks.jsonl, manifest.json, quality_report.json) ë‚´ë ¤ë°›ì•„ ë³µêµ¬
# 3) ê·¸ë˜ë„ ì—†ìœ¼ë©´: PREPARED í´ë”ì—ì„œ ìœ„ 3ê°œë¥¼ ì°¾ì•„ ë‚´ë ¤ë°›ê³  â†’ ZIPìœ¼ë¡œ ë¬¶ì–´ BACKUP í´ë”ì— ì—…ë¡œë“œ(ë°±ì—… ìë™ìƒì„±)
# 4) ì „ë¶€ ì—†ìœ¼ë©´: ê´€ë¦¬ìê°€ íŒŒì¼ ì—…ë¡œë“œ â†’ ZIPìœ¼ë¡œ ë¬¶ì–´ BACKUPì— ì˜¬ë¦° ë’¤ ë³µêµ¬

import json, io, os, zipfile
from pathlib import Path
from typing import Any, Mapping, Iterator, Tuple, List, Optional

import streamlit as st

# --- ê³µí†µ ìƒìˆ˜ ----------------------------------------------------------------
REQ_FILES = ["chunks.jsonl", "manifest.json", "quality_report.json"]

# --- (A) ì‹œí¬ë¦¿ ì „ìˆ˜ì¡°ì‚¬ -----------------------------------------------------
def _iter_secrets(obj: Any, prefix: str = "") -> Iterator[Tuple[str, Any]]:
    try:
        from collections.abc import Mapping as _Mapping
        if isinstance(obj, _Mapping):
            for k, v in obj.items():
                path = f"{prefix}.{k}" if prefix else str(k)
                yield from _iter_secrets(v, path)
        else:
            yield (prefix, obj)
    except Exception:
        yield (prefix, obj)

def _flatten_secrets() -> list[Tuple[str, Any]]:
    return list(_iter_secrets(st.secrets))

# --- (B) ì„œë¹„ìŠ¤ê³„ì • JSON ìë™ íƒìƒ‰ -------------------------------------------
def _find_service_account_in_secrets() -> dict:
    preferred = (
        "GDRIVE_SERVICE_ACCOUNT_JSON",
        "GOOGLE_SERVICE_ACCOUNT_JSON",
        "SERVICE_ACCOUNT_JSON",
        "gdrive_service_account_json",
        "service_account_json",
        "GCP_SERVICE_ACCOUNT",
        "gcp_service_account",
    )
    for key in preferred:
        if key in st.secrets and str(st.secrets[key]).strip():
            raw = st.secrets[key]
            return json.loads(raw) if isinstance(raw, str) else dict(raw)

    candidates: list[tuple[str, dict]] = []
    for path, val in _flatten_secrets():
        try:
            from collections.abc import Mapping as _Mapping
            if isinstance(val, _Mapping):
                if val.get("type") == "service_account" and "client_email" in val and "private_key" in val:
                    candidates.append((path, dict(val)))
            elif isinstance(val, str):
                if '"type": "service_account"' in val and '"client_email"' in val and '"private_key"' in val:
                    candidates.append((path, json.loads(val)))
        except Exception:
            continue
    if candidates:
        candidates.sort(key=lambda kv: (
            0 if any(tok in kv[0].upper() for tok in ("RAG", "GDRIVE", "SERVICE")) else 1,
            len(kv[0]),
        ))
        return candidates[0][1]
    raise KeyError("ì„œë¹„ìŠ¤ê³„ì • JSONì„ ì‹œí¬ë¦¿ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# --- (C) í´ë” ID ìë™ íƒìƒ‰ ---------------------------------------------------
def _find_folder_id(kind: str) -> Optional[str]:
    """
    kind: 'BACKUP' | 'PREPARED' | 'DEFAULT'
    ì‹œí¬ë¦¿ì—ì„œ ëŒ€ì‘ í‚¤ë¥¼ ì°¾ëŠ”ë‹¤. (ì¤‘ì²© í¬í•¨)
    """
    key_sets = {
        "BACKUP": ("GDRIVE_BACKUP_FOLDER_ID", "BACKUP_FOLDER_ID"),
        "PREPARED": ("GDRIVE_PREPARED_FOLDER_ID", "PREPARED_FOLDER_ID"),
        "DEFAULT": ("GDRIVE_FOLDER_ID",),
    }
    for key in key_sets.get(kind, ()):
        if key in st.secrets and str(st.secrets[key]).strip():
            return str(st.secrets[key]).strip()
    for path, val in _flatten_secrets():
        try:
            if isinstance(val, (str, int)) and "FOLDER_ID" in path.upper() and str(val).strip():
                up = path.upper()
                if kind == "BACKUP" and "BACKUP" in up:
                    return str(val).strip()
                if kind == "PREPARED" and "PREPARED" in up:
                    return str(val).strip()
                if kind == "DEFAULT" and "GDRIVE_FOLDER_ID" in up:
                    return str(val).strip()
        except Exception:
            continue
    return None

# --- (D) Drive ìœ í‹¸ ----------------------------------------------------------
def _drive_client():
    try:
        from google.oauth2.service_account import Credentials
        from googleapiclient.discovery import build
    except Exception as e:
        raise RuntimeError("google-api-python-client / google-auth íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.") from e
    sa_info = _find_service_account_in_secrets()
    creds = Credentials.from_service_account_info(sa_info, scopes=["https://www.googleapis.com/auth/drive"])
    return build("drive", "v3", credentials=creds, cache_discovery=False)

def _download_file_to(service, file_id: str, out_path: Path) -> None:
    from googleapiclient.http import MediaIoBaseDownload
    out_path.parent.mkdir(parents=True, exist_ok=True)
    req = service.files().get_media(fileId=file_id)
    buf = io.BytesIO()
    downloader = MediaIoBaseDownload(buf, req)
    done = False
    while not done:
        _, done = downloader.next_chunk()
    buf.seek(0)
    out_path.write_bytes(buf.read())

def _find_latest_zip(service, folder_id: str):
    q = f"'{folder_id}' in parents and trashed=false and mimeType='application/zip'"
    resp = service.files().list(q=q, orderBy="modifiedTime desc",
                                fields="files(id,name,modifiedTime,size)", pageSize=1).execute()
    files = resp.get("files", [])
    return files[0] if files else None

def _find_named_files(service, folder_id: str, names: List[str]) -> dict:
    found = {}
    for nm in names:
        q = f"'{folder_id}' in parents and trashed=false and name='{nm}'"
        resp = service.files().list(q=q, fields="files(id,name,size,modifiedTime)", pageSize=1).execute()
        files = resp.get("files", [])
        if files:
            found[nm] = files[0]
    return found

def _upload_zip(service, folder_id: str, path: Path, name: str) -> str:
    media = None
    from googleapiclient.http import MediaFileUpload
    media = MediaFileUpload(str(path), mimetype="application/zip", resumable=False)
    file_metadata = {"name": name, "parents": [folder_id], "mimeType": "application/zip"}
    created = service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    return created.get("id")

# --- (E) ë¡œì»¬ ê²½ë¡œ -----------------------------------------------------------
def _app_data_dir() -> Path:
    try:
        from src.config import APP_DATA_DIR
        return Path(APP_DATA_DIR)
    except Exception:
        return Path(os.getenv("APP_DATA_DIR") or (Path.home() / ".maic"))

def _ensure_local_index_dir() -> Path:
    p = _app_data_dir()
    p.mkdir(parents=True, exist_ok=True)
    return p

def _zip_local_index(zip_path: Path) -> None:
    base = _ensure_local_index_dir()
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for fn in REQ_FILES:
            fp = base / fn
            if fp.exists():
                zf.write(fp, arcname=fn)

# --- (F) í•µì‹¬: ë³µêµ¬/ìƒì„± íŒŒì´í”„ë¼ì¸ -----------------------------------------
def _restore_or_make_backup():
    svc = _drive_client()
    # í´ë” íƒìƒ‰ ìš°ì„ ìˆœìœ„
    backup_folder = _find_folder_id("BACKUP") or _find_folder_id("DEFAULT")
    prepared_folder = _find_folder_id("PREPARED")

    if not backup_folder:
        raise KeyError("ë°±ì—… í´ë” IDë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (GDRIVE_BACKUP_FOLDER_ID ë˜ëŠ” GDRIVE_FOLDER_ID)")

    local_dir = _ensure_local_index_dir()

    # 1) ZIP ìš°ì„  ë³µêµ¬
    z = _find_latest_zip(svc, backup_folder)
    if z:
        buf_zip = local_dir / "_restore.zip"
        _download_file_to(svc, z["id"], buf_zip)
        with zipfile.ZipFile(buf_zip) as zf:
            zf.extractall(local_dir)
        buf_zip.unlink(missing_ok=True)
        return {"mode": "zip_restore", "from": "BACKUP", "name": z.get("name")}

    # 2) BACKUP í´ë”ì˜ ëŠìŠ¨í•œ íŒŒì¼ ë³µêµ¬
    loose = _find_named_files(svc, backup_folder, REQ_FILES)
    if len(loose) >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì´ë©´ ë³µêµ¬ ì‹œë„
        for nm, meta in loose.items():
            _download_file_to(svc, meta["id"], local_dir / nm)
        # ë³´ë„ˆìŠ¤: ë¯¸ë˜ ì‚¬ìš©ì„ ìœ„í•´ ZIP ìƒì„± & ì—…ë¡œë“œ
        tmp_zip = local_dir / "_made_from_loose.zip"
        _zip_local_index(tmp_zip)
        _upload_zip(svc, backup_folder, tmp_zip, "index_backup.zip")
        tmp_zip.unlink(missing_ok=True)
        return {"mode": "loose_restore", "from": "BACKUP", "files": list(loose.keys())}

    # 3) PREPARED í´ë”ì—ì„œ ì¤€ë¹„ë¬¼ ê°€ì ¸ì™€ ZIP ë§Œë“¤ì–´ BACKUPì— ì €ì¥ í›„ ë³µêµ¬
    if prepared_folder:
        prep = _find_named_files(svc, prepared_folder, REQ_FILES)
        if len(prep) >= 2:
            for nm, meta in prep.items():
                _download_file_to(svc, meta["id"], local_dir / nm)
            tmp_zip = local_dir / "_made_from_prepared.zip"
            _zip_local_index(tmp_zip)
            _upload_zip(svc, backup_folder, tmp_zip, "index_backup.zip")
            tmp_zip.unlink(missing_ok=True)
            return {"mode": "made_from_prepared", "from": "PREPARED", "files": list(prep.keys())}

    # 4) ì „ë¶€ ì—†ìœ¼ë©´: ìˆ˜ë™ ì—…ë¡œë“œ UIë¡œ ì²˜ë¦¬í•˜ë„ë¡ ì‹ í˜¸
    return {"mode": "need_manual_upload"}

# --- (G) UI ------------------------------------------------------------------
st.subheader("RAG: Restore / Make Backup")
col1, col2 = st.columns(2)
with col1:
    _b = _find_folder_id("BACKUP") or _find_folder_id("DEFAULT") or ""
    st.text_input("Backup folder ID", value=_b, disabled=True)
with col2:
    _p = _find_folder_id("PREPARED") or ""
    st.text_input("Prepared folder ID (optional)", value=_p, disabled=True)

if st.button("ğŸ” Restore (zip â†’ loose â†’ prepared) / Make backup"):
    with st.spinner("Running restore/make pipelineâ€¦"):
        try:
            res = _restore_or_make_backup()
            mode = res.get("mode")
            if mode == "need_manual_upload":
                st.warning("ë°±ì—… ZIP/ëŠìŠ¨í•œ íŒŒì¼/ì¤€ë¹„ë¬¼ ëª¨ë‘ ì—†ìŒ â†’ ì•„ë˜ ìˆ˜ë™ ì—…ë¡œë“œë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.")
            else:
                st.success(f"Done via: {mode} from {res.get('from')}")
                st.caption(str({k: v for k, v in res.items() if k not in ('mode',)}))
                # ë³µêµ¬ ì§í›„ ì¸ë±ìŠ¤ ì¬ì‹œë„
                try:
                    idx = get_or_build_index() if get_or_build_index else None
                    if idx is not None:
                        st.session_state["rag_index"] = idx
                        st.success("Index loaded.")
                except Exception as e:
                    st.warning(f"Index reload skipped: {type(e).__name__}: {e}")
        except Exception as e:
            st.error(f"{type(e).__name__}: {e}")

# --- (H) ìˆ˜ë™ ì—…ë¡œë“œ(ìµœí›„ì˜ ë³´ë£¨) --------------------------------------------
st.markdown("**Manual upload (ìµœí›„ì˜ ë³´ë£¨)** â€” ì•„ë˜ 3ê°œ ì¤‘ ë³´ìœ í•œ íŒŒì¼ë§Œ ì˜¬ë ¤ë„ ë©ë‹ˆë‹¤.")
u_cols = st.columns(3)
up = {
    "chunks.jsonl": u_cols[0].file_uploader("chunks.jsonl", type=["jsonl"]),
    "manifest.json": u_cols[1].file_uploader("manifest.json", type=["json"]),
    "quality_report.json": u_cols[2].file_uploader("quality_report.json", type=["json"]),
}
if st.button("â¬†ï¸ Save locally & make BACKUP zip"):
    try:
        base = _ensure_local_index_dir()
        saved = []
        for nm, fl in up.items():
            if fl is not None:
                p = base / nm
                p.write_bytes(fl.read())
                saved.append(nm)
        if not saved:
            st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            tmp_zip = base / "_uploaded_make.zip"
            _zip_local_index(tmp_zip)
            # ì—…ë¡œë“œ ëŒ€ìƒ í´ë”
            bfolder = _find_folder_id("BACKUP") or _find_folder_id("DEFAULT")
            if not bfolder:
                raise KeyError("ë°±ì—… í´ë” IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            svc = _drive_client()
            _upload_zip(svc, bfolder, tmp_zip, "index_backup.zip")
            tmp_zip.unlink(missing_ok=True)
            st.success(f"Saved locally: {saved} â†’ backup zip uploaded.")
            # ë³µêµ¬ ì§í›„ ì¸ë±ìŠ¤ ì¬ì‹œë„
            try:
                idx = get_or_build_index() if get_or_build_index else None
                if idx is not None:
                    st.session_state["rag_index"] = idx
                    st.success("Index loaded from uploaded files.")
            except Exception as e:
                st.warning(f"Index reload skipped: {type(e).__name__}: {e}")
    except Exception as e:
        st.error(f"{type(e).__name__}: {e}")

# ===== [03] END ==============================================================

# ===== [03] END ==============================================================
